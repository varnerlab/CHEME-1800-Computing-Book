{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0270db7",
   "metadata": {},
   "source": [
    "# Probability and Uncertain Choices\n",
    "\n",
    "Uncertain decisions are those that involve a certain degree of risk or ambiguity. Uncertain decisions arise in many situations, such as investing in the stock market, choosing a career path, making technical choices, or deciding whether to pursue a romantic relationship. Making uncertain decisions involves weighing each option’s potential benefits and drawbacks and considering the likelihood of different outcomes.\n",
    "\n",
    "In this lecture, we introduce tools to model and analyze simple uncertain decisions:\n",
    "\n",
    "* {ref}`content:references:utility-and-utlity-max` is the process of selecting the option that provides the highest level of satisfaction, or utility, based on the individual's preferences and constraints. This concept is often used in economics to model consumer behavior and in decision theory to analyze choices under uncertainty.\n",
    "\n",
    "* {ref}`content:references:utility-and-uncetain-decisions` are decision-making situations where the outcomes of different options are unknown or uncertain. These types of decisions often involve risk and involve balancing the potential rewards and risks of different options. To make optimal choices under uncertainty, decision-makers may use probabilistic tools such as expected utility theory to analyze the expected outcomes of different options.\n",
    "\n",
    "---\n",
    "\n",
    "(content:references:utility-and-utlity-max)=\n",
    "## Utility maximization\n",
    "A utility function is a mathematical expression representing an individual's preferences over different choices or outcomes. It assigns a numerical value, called _utility_, to each possible option based on how much the individual values it. A utility function is subjective and can vary from person to person, as different individuals may have other preferences.\n",
    "\n",
    "[Rational choice theory](https://en.wikipedia.org/wiki/Rational_choice_theory) assumes individuals make rational decisions based on their preferences and available information. [Rational choice theory](https://en.wikipedia.org/wiki/Rational_choice_theory) is based on computing the utility of actions or outcomes. Thus, utility functions are a crucial component of this theory, as they describe how individuals assign values to different results or choices ({prf:ref}`defn-individual-utility`):\n",
    "\n",
    "````{prf:definition} Ordinal utility function\n",
    ":label: defn-individual-utility\n",
    "\n",
    "An individual decision-making agent is presented with a bundle of $n$ objects $x_{1},\\dots,x_{n}$. A utility function represents the preference of the agent for combinations of these $n$ objects:\n",
    "\n",
    "```{math}\n",
    ":label: eqn-utility-function-generic\n",
    "U(x_{1},x_{2},\\dots,x_{n})\n",
    "```\n",
    "\n",
    "The utility function $U(\\dots)$ is unique only up to an order-preserving transformation in period $t\\rightarrow{t+dt}$. Further, utility functions are ordinal, i.e., they rank-order bundles but do not indicate how much better a bundle is compared to another.\n",
    "\n",
    "````\n",
    "\n",
    "{prf:ref}`defn-individual-utility` does not give specifics about the properties of a utility function. However, it does establish a critical concept; the utility can be used to rank order the preference for different choices. For example, suppose we have two choices, $A$ and $B$:\n",
    "\n",
    "* If $A\\succ{B}$, the decision maker _strictly prefers_ $A$ to $B$. Then, the utility of choice $A$ is greater than $B$, or $U(A)>U(B)$.\n",
    "* If $A\\sim{B}$, the decision maker is _indifferent_ between $A$ to $B$. Then, the utility of choice $A$ is the same as $B$, or $U(A)=U(B)$.\n",
    "* If $A\\succsim{B}$, the decision maker _weakly prefers_ $A$ over $B$, or they are indifferent. Then, the utility of choice $A$ is greater than or equal to $B$, or $U(A)\\geq{U(A)}$.\n",
    "\n",
    "### Properties of utility functions\n",
    "A utility function is a mathematical representation of a person's preferences over different outcomes or alternatives. Here are some properties that a utility function should possess:\n",
    "\n",
    "* __Completeness__: A utility function should be able to rank all possible outcomes or alternatives. In other words, for any two outcomes, the utility function should tell us which one is preferred or whether they are equally preferred.\n",
    "* __Transitivity__: If outcome A is preferred to outcome B, and outcome B is preferred to outcome C, then outcome A must be preferred to outcome C. This is known as the transitivity property.\n",
    "* __Monotonicity__: If more of a good is always preferred to less, then the utility function should increase in that good. Conversely, if less of a bad is always preferred to more, then the utility function should decrease in that bad.\n",
    "* __Continuity__: Small changes in the outcome or alternatives should result in small changes in the utility function. This is known as the continuity property.\n",
    "* __Concavity__: The utility function should be concave if the person exhibits diminishing marginal utility. This means that as a person consumes more of a good, the additional satisfaction gained from each unit consumed decreases.\n",
    "\n",
    "These properties help ensure that a utility function accurately represents a person's preferences and can be used to make rational choices between alternatives.\n",
    "\n",
    "#### Marginal utility\n",
    "The marginal utility is the additional satisfaction or usefulness an agent derives from consuming one additional unit of a good or service. Mathematically, the marginal utility is the partial derivative of the utility with respect to the amount of item $i$ ({prf:ref}`defn-marginal-utility-math`):\n",
    "\n",
    "````{prf:definition} Marginal utility\n",
    ":label: defn-marginal-utility-math\n",
    "\n",
    "The preference or satisfaction derived from a bundle of objects $x_{1},\\dots,x_{n}$ is described by the utility function $U(x_{1},\\dots,x_{n})$. Then, the satisfaction experienced by the agent from one additional unit of the object $i$ in the bundle is defined as the marginal utility of object $i$:\n",
    "\n",
    "```{math}\n",
    "\\text{MU}^{\\star}_{i} \\equiv \\left(\\frac{\\partial{U}}{\\partial{x_{i}}}\\right)_{\\star}\\qquad{i=1,2,\\dots,n}\n",
    "```\n",
    "\n",
    "where all other objects are held constant at level $\\star$.\n",
    "````\n",
    "\n",
    "##### Analytical marginal utility \n",
    "The marginal utility can be computed by directly differentiating the utility function. For example, consider an example utility function that we'll use later, the [Cobb-Douglas utility function](https://en.wikipedia.org/wiki/Cobb–Douglas_production_function). The [Cobb–Douglas utility function](https://en.wikipedia.org/wiki/Cobb–Douglas_production_function) governing the satisfaction gained by consuming a bundle of $n$ goods $(x_{1},x_{2},\\dots,x_{n})$ is given by:\n",
    "\n",
    "```{math}\n",
    ":label: eqn-cobb-douglas-u-function\n",
    "U(x)  = \\prod_{i=1}^{n}x_{i}^{\\alpha_{i}} \n",
    "```\n",
    "\n",
    "where the coefficients $\\alpha_{i}$ are governed by:\n",
    "\n",
    "```{math}\n",
    "\\sum_{i=1}^{n}\\alpha_{i}  = 1\n",
    "```\n",
    "\n",
    "The [Cobb–Douglas utility function](https://en.wikipedia.org/wiki/Cobb–Douglas_production_function) satisfies the utility function properties, where the marginal utility is given by: \n",
    "\n",
    "```{math}\n",
    ":label: eqn-mu-u-function\n",
    "\n",
    "\\text{MU}_{x_{i}} = \\left(\\alpha_{i}x^{\\alpha_{i}-1}\\right)\\cdot\\left(\\prod_{j=1,i}^{n}x_{j}^{\\alpha_{j}}\\right)\n",
    "```\n",
    "\n",
    "where the $j=1,i$ notation denotes the _exclusion_ of index $i$. As $x_{i}\\rightarrow\\infty$, the marginal utility $\\text{MU}_{x_{i}}\\rightarrow{0}$ if $\\alpha_{i}<1$. Thus, the convexity property is satisfied for $\\alpha_{i}<1$. Alternatively, to compute analytical expressions for the marginal utility, instead of remembering the [differentiation rules from calculus](https://en.wikipedia.org/wiki/Differentiation_rules), we can use one of many [Computer Algebra Systems (CAS)](https://en.wikipedia.org/wiki/Computer_algebra_system), e.g., the [Symbolics.jl](https://github.com/JuliaSymbolics/Symbolics.jl) package in [Julia](https://julialang.org) or the [SymPy](https://www.sympy.org/en/index.html) library in [Python](https://www.python.org).\n",
    "\n",
    "Sample code to compute the marginal utility for the two-dimensional [Cobb-Douglas utility function](https://en.wikipedia.org/wiki/Cobb–Douglas_production_function) using the [Symbolics.jl](https://github.com/JuliaSymbolics/Symbolics.jl) package:\n",
    "\n",
    "```julia\n",
    "# load the Symbolics.jl package (assumed to be installed)\n",
    "using Symbolics\n",
    "\n",
    "# declare variables (symbols in the eqn)\n",
    "@variables x,y,α,β\n",
    "\n",
    "# Build differential operators for x\n",
    "Dₓ = Differential(x);\n",
    "\n",
    "# define the utility function\n",
    "U = (x^α)*(y^β)\n",
    "\n",
    "# compute the derivative -\n",
    "∂Uₓ = Dₓ(U) |> expand_derivatives;\n",
    "\n",
    "# print -\n",
    "println(\"The value of ∂U/∂x = \",∂Uₓ)\n",
    "```\n",
    "\n",
    "##### Numerical marginal utility \n",
    "However, sometimes it may not be convenient to analytically compute the derivative, e.g., the utility function is complicated. You can always approximate the marginal utility using a [finite difference approximation](https://en.wikipedia.org/wiki/Finite_difference), or [automatic differentiation](https://en.wikipedia.org/wiki/Automatic_differentiation) approach.\n",
    "\n",
    "Sample code for [automatic differentiation](https://en.wikipedia.org/wiki/Automatic_differentiation) of the Cobb-Douglas utility function using the [ForwardDiff.jl](https://juliadiff.org/ForwardDiff.jl/stable/) package:\n",
    "\n",
    "```julia\n",
    "# load the ForwardDiff package\n",
    "using ForwardDiff\n",
    "\n",
    "# Cobb-Douglas utility function\n",
    "function U(x)\n",
    "\n",
    "    # initialize\n",
    "    α₁ = 0.5;\n",
    "    α₂ = 1.0 - α₁\n",
    "    \n",
    "    # return\n",
    "    return (x[1]^α₁)*(x[2]^α₂)\n",
    "end\n",
    "\n",
    "# Estimate the MU -\n",
    "x = [20.0,7.20]; # point A \n",
    "MU = ForwardDiff.gradient(U,x);\n",
    "```\n",
    "\n",
    "##### Aside: Marginal utility of wealth\n",
    "The marginal utility quantifies the satisfaction gained by an agent from an additional unit of consumption of a good or service ({numref}`fig-wealth-schematic-simple-model`).\n",
    "\n",
    " ```{figure} ./figs/Fig-Wealth-Utility-Schematic.pdf\n",
    "---\n",
    "height: 400px\n",
    "name: fig-wealth-schematic-simple-model\n",
    "---\n",
    "Wealth utility function $U(W) = W/(W+b)$ as a function of choices for the parameter $b$. The abundance of wealth is inversely proportional to the value of the parameter $b$. For example, the agent at $A$ values each additional wealth unit less than the agent at $D$.\n",
    "```\n",
    "\n",
    "The relationship between overall resource level (wealth) and the marginal utility of resources is a fundamental concept in economics that explains how individuals value resources and other material possessions. Marginal utility is basic to how an agent values a good or service, including wealth. According to this concept, the more wealth a person has, the less value each additional unit of wealth provides in terms of satisfaction or well-being. This is because as a person's wealth increases, the marginal utility of each additional wealth unit decreases due to the [diminishing marginal utility of money](https://en.wikipedia.org/wiki/Marginal_utility).\n",
    "\n",
    "### Indifference curves\n",
    "Indifference curves are graphical representations of combinations of choices that provide a decision-making agent with the same level of utility ({numref}`fig-cobb-douglas-ic`). Thus, decision-makers are _indifferent_ to the consumption of different combinations of goods (or services) on an indifference curve. \n",
    "\n",
    " ```{figure} ./figs/Fig-CobbDouglas-IndifferenceCurves-Sqrt.pdf\n",
    "---\n",
    "height: 400px\n",
    "name: fig-cobb-douglas-ic\n",
    "---\n",
    "Two-dimensional indifference curves were generated using the Cobb–Douglas utility function with $\\alpha_{1} = \\alpha_{2} = 0.5$. The decision maker is indifferent to a choice between point $A$ and $B$, i.e., $A\\sim{B}$ or $C\\sim{D}$. However, the decision maker strictly prefers $C$ and $D$ compared to $A$ and $B$, i.e., $C\\sim{D}\\succ{A}\\sim{B}$.\n",
    "```\n",
    "\n",
    "For example, the decision agent with the Cobb–Douglas utility function shown in ({numref}`fig-cobb-douglas-ic`) is _indifferent_ to a choice between $A$ and $B$, but strictly prefers $C$ and $D$ to either $A$ or $B$. \n",
    "\n",
    "Sample code to compute the two-dimensional indifference curve for a Cobb–Douglas utility function with $\\alpha_{1} = \\alpha_{2} = 0.5$:\n",
    "```julia\n",
    "# initialize\n",
    "α₁ = 0.5 \n",
    "α₂ = 1.0 - α₁\n",
    "\n",
    "# Storage: holds indifference curves \n",
    "results = Dict{Int64,Array{Float64,2}}()\n",
    "\n",
    "# Set values for the good and service 1\n",
    "X1 = range(0.001,stop=100.0,step = 0.001) |> collect;\n",
    "d = length(X1);\n",
    "\n",
    "# Set utility values\n",
    "U = [12.0, 24.0, 36.0, 48.0];\n",
    "n = length(U);\n",
    "\n",
    "# simulation loop\n",
    "for i ∈ 1:n\n",
    "\n",
    "    # Allocate storage for the indifference curve \n",
    "    Y = Array{Float64,2}(undef,d,2);\n",
    "    U_val = U[i];\n",
    "\n",
    "    # compute X2 from the X1 values\n",
    "    for j ∈ 1:d\n",
    "\n",
    "        # compute the log-transformed utility\n",
    "        tmp = (1/α₂)*(log(U_val) - α₁*log(X1[j]));\n",
    "\n",
    "        # store\n",
    "        Y[j,1] = X1[j];\n",
    "        Y[j,2] = exp(tmp); # inverse transform\n",
    "    end\n",
    "\n",
    "    # store -\n",
    "    results[i] = Y;\n",
    "end\n",
    "```\n",
    "\n",
    "### Marginal rate of substitution\n",
    "How much of one good or service a decision maker is willing to trade for another is called the [marginal rate of substution](https://en.wikipedia.org/wiki/Marginal_rate_of_substitution) ({prf:ref}`defn-marginal-rate-of-sub`):\n",
    "\n",
    "````{prf:definition} Marginal Rate of Substitution\n",
    ":label: defn-marginal-rate-of-sub\n",
    "\n",
    "A decision maker is analyzing the consumption of different combinations of $n$ goods or services $x_{1},\\dots,x_{n}$. The utility \n",
    "function governing the decision maker $U(\\dots)$ can be expanded by computing the [total differential](https://en.wikipedia.org/wiki/Differential_of_a_function#Differentials_in_several_variables) around some point $\\left(x_{1}^{\\star},\\dots,x_{n}^{\\star}\\right)$ on an indifference curve with utility $c$:\n",
    "\n",
    "```{math}\n",
    ":label: eqn-total-differential-ic\n",
    "\n",
    "dU = \\sum_{i=1}^{n}\\left(\\frac{\\partial{U}}{\\partial{x_{i}}}\\right)_{\\star}dx_{i}\n",
    "```\n",
    "\n",
    "The partial derivative of the utility with respect to a change in the consumption of good or service $i$ is the [marginal utility](https://en.wikipedia.org/wiki/Marginal_utility):\n",
    "\n",
    "```{math}\n",
    "dU = \\sum_{i=1}^{n}\\left(\\text{MU}_{i}^{\\star}\\right){dx_{i}}\n",
    "```\n",
    "\n",
    "The utility $U(\\dots)=c$ on an indifference curve; thus, along an indifference curve $dU = 0$. The marginal rate of substitution of good or service $i$ for $j$ (all other quantities held constant):\n",
    "\n",
    "```{math}\n",
    ":label: eqn-total-differential-ic-constant\n",
    "\n",
    "\\text{MU}^{\\star}_{i}dx_{i} + \\text{MU}^{\\star}_{j}dx_{j} = 0\\qquad{i\\neq{j}}\n",
    "```\n",
    "\n",
    "can be computed for good $i$ and $j$:\n",
    "\n",
    "```{math}\n",
    ":label: eqn-total-differential-ic-mrs\n",
    "\\text{MRS}^{\\star}_{ij} = -\\frac{dx_{j}}{dx_{i}} = \\frac{\\text{MU}^{\\star}_{i}}{\\text{MU}^{\\star}_{j}}\\qquad\\forall\\left(i,j\\right)_{i\\neq{j}}\n",
    "```\n",
    "\n",
    "````\n",
    "\n",
    "### Optimal choices and budgets\n",
    "An optimal decision-making agent _maximizes_ its utility function, i.e., the agent searches for a combination of goods and services that gives the highest satisfaction subject to various constraints, e.g., a budget constraint ({prf:ref}`eqn-budget-constraint`):\n",
    "\n",
    "````{prf:definition} Maximum utility and budget constraints\n",
    ":label: eqn-budget-constraint\n",
    "\n",
    "A decision making agent has a utility function $U\\left(x_{1},\\dots,x_{n}\\right)$ and $I$ dollars to spend between $t\\rightarrow{t+dt}$. An optimal agent maximizes its utility subject to its budget:\n",
    "\n",
    "```{math}\n",
    ":label: eqn-max-ulity-problem\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\text{maximize}~\\mathcal{O} &=& U\\left(x_{1},\\dots,x_{n}\\right) \\\\\n",
    "\\text{subject to}~\\sum_{i=1}^{n}c_{i}x_{i} & \\leq & I\\\\\n",
    "\\text{and}~x_{i}&\\geq&{0}\\qquad{i=1,2,\\dots,n}\n",
    "\\end{eqnarray}\n",
    "\n",
    "```\n",
    "\n",
    "where $c_{i}\\geq{0}~\\forall{i}$ denotes the cost of good or service $i$, and $x_{i}$ represents the amount of good or service purchased or consumed by the agent during time period $t\\rightarrow{t+dt}$.\n",
    "\n",
    "````\n",
    "\n",
    "The problem in {prf:ref}`eqn-budget-constraint` can be solved for the unknown consumption levels of $x_{i}$ using various techniques. For example, we could use the [method of Lagrange multipliers](https://en.wikipedia.org/wiki/Lagrange_multiplier) or a [penalty method](https://en.wikipedia.org/wiki/Penalty_method) in combination with any number of heuristic optimization approaches, e.g., [simulated annealing](https://en.wikipedia.org/wiki/Simulated_annealing). Of course, if the utility function in {prf:ref}`eqn-budget-constraint` is linear, we could also use [linear programming](https://en.wikipedia.org/wiki/Linear_programming).\n",
    "\n",
    "Let's do an example of a decision between two goods using a Cobb–Douglas utility function subject to a budget constraint ({prf:ref}`example-utility-max-budget`):\n",
    "\n",
    "````{prf:example} Maximize utility subject to budget\n",
    ":label: example-utility-max-budget\n",
    ":class: dropdown\n",
    "\n",
    "__Problem__: A decision making agent must decide how much of two goods to consume, $x_{1}$ and $x_{2}$, subject to a budget constraint. Good one costs 18.0 USD per unit, while good two costs 36.0 USD per unit. The agent has 100.0 USD to spend and is governed by a Cobb–Douglas utility function with $\\alpha_{1} = 0.45$ and  $\\alpha_{2} = 0.55$. Compute the optimal mixture of $x_{1}$ and $x_{2}$.\n",
    "\n",
    "````\n",
    "\n",
    "\n",
    "(content:references:utility-and-uncetain-decisions)=\n",
    "## Choices under uncertainty\n",
    "In the previous section, we developed tools to make optimal choices when the outcomes were sure, and the level of satisfaction derived from those choices was known, e.g., the utility of purchasing a particular bundle of goods or services could be computed using a utility function. However, in many real-world situations, the assumption of certainty is invalid. For example, betting, buying an insurance policy or investing in a new business, or the stock market all or _uncertain_. \n",
    "\n",
    "\n",
    "To understand how optimal agents behave when faced with uncertain situations, we define the [von Neumann-Morgenstern theorem](https://en.wikipedia.org/wiki/Von_Neumann–Morgenstern_utility_theorem), which provides a basis for computing an optimal decision in an uncertain situation. \n",
    "\n",
    "### The von Neumann - Morgenstern theorem\n",
    "The [von Neumann-Morgenstern theorem](https://en.wikipedia.org/wiki/Von_Neumann–Morgenstern_utility_theorem), also known as the [expected utility hypothesis](https://en.wikipedia.org/wiki/Expected_utility_hypothesis), is a fundamental result in decision theory that provides a framework for making _rational choices_ under uncertainty {cite}`vonneumann1947` ({prf:ref}`defn-expected-utility-hypothesis`):\n",
    "\n",
    "````{prf:definition} Expected utility hypothesis\n",
    ":label: defn-expected-utility-hypothesis\n",
    "\n",
    "An agent chooses amongst $n$ possible uncertain objects, $x_{1},\\dots,x_{n}$ where object $k$ has a probability $p_{k}$ of occuring and a utility payoff of $U(x_{k})$. A _rational decision maker_ maximizes the expected utility subject to constraints:\n",
    "\n",
    "\n",
    "```{math}\n",
    ":label: eqn-max-expected-ulity-problem\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\text{maximize}~\\mathcal{O} &=& \\sum_{k=1}^{n}p_{k}U(x_{k}) \\\\\n",
    "\\text{subject to}~g(x)~& \\leq & 0\\\\\n",
    "\\text{and}~x_{k}&\\geq&{0}\\qquad{k=1,2,\\dots,n}\n",
    "\\end{eqnarray}\n",
    "\n",
    "```\n",
    "\n",
    "where $p_{k}$ denotes the probability of object $k$, and $g(x)$ denotes potentially non-linear constraints governing the objects $x_{1},\\dots,x_{n}$.\n",
    "````\n",
    "\n",
    "The [von Neumann-Morgenstern theorem](https://en.wikipedia.org/wiki/Von_Neumann–Morgenstern_utility_theorem) depends upon an understanding of two critical concepts, random variables, and probability:\n",
    "\n",
    "* A [random variable](https://en.wikipedia.org/wiki/Random_variable) is a variable $X$ that takes on different values $x$ according to the outcome of a random event or process. There are two types of random variables: discrete random variables and continuous random variables. Discrete random variables can take on a countable number of distinct values, while continuous random variables can take on any value in a continuous range. \n",
    "* [Probability](https://en.wikipedia.org/wiki/Probability) measures the likelihood that a particular event or outcome will occur and is commonly used to quantify uncertainty in various fields, such as science, engineering, economics, and finance. For a discrete random variable, the likelihood that $X=x$ is described by a [Probability Mass Function (PMF)](https://en.wikipedia.org/wiki/Probability_mass_function) and a [Probability Density Function (PDF)](https://en.wikipedia.org/wiki/Probability_density_function) for continuous random variables.  \n",
    "\n",
    "#### Probability mass functions\n",
    "In the case of discrete random variables, for example, dice roles, coin flips etc, the likelihood that $X=x$ is described by a [Probability Mass Function (PMF)](https://en.wikipedia.org/wiki/Probability_mass_function) ({prf:ref}`defn-pmf`):\n",
    "\n",
    "````{prf:definition} Probability Mass Function\n",
    ":label: defn-pmf\n",
    "\n",
    "The probability mass function (PMF) of a discrete random variable $X$ is a function that specifies the probability of obtaining $X = x$, where $x$ is a particular event in the set of possible events we're interested in $\\mathcal{F}\\subseteq{X\\left(\\Omega\\right)}$:\n",
    "\n",
    "$$p_{X}(x) = P\\left(X=x\\right)$$\n",
    "\n",
    "where $\\mathcal{F}$ is the event space, and $\\Omega$ is the sample space. A probability mass function must satisfy the condition: \n",
    "\n",
    "$$\\sum_{x\\in{X(\\Omega)}}p_{X}(x)=1$$\n",
    "````\n",
    "\n",
    "Thus, in the context of the [von Neumann-Morgenstern theorem](https://en.wikipedia.org/wiki/Von_Neumann–Morgenstern_utility_theorem), the probability mass function is a weight for discrete random variables which model uncertain payoffs. \n",
    "\n",
    "In [Julia](https://julialang.org), probability mass (or density) functions can be constructed and sampled using the [Distributions.jl](https://juliastats.org/Distributions.jl/stable/) package. Let's look at a few common probability mass functions.\n",
    "\n",
    "##### Bernoulli random variable\n",
    "A Bernoulli random variable, the simplest random variable, models a coin flip or some other type of binary\n",
    "outcome ({prf:ref}`defn-pmf-bernouli`):\n",
    "\n",
    "````{prf:definition} Bernoulli Random Variable\n",
    ":label: defn-pmf-bernouli\n",
    "\n",
    "Let $X$ be a Bernoulli random variable. Then, the probability mass function of $X$ is given by:\n",
    "\n",
    "```{math}\n",
    "p_{X}(x) =\n",
    "\\begin{cases}\n",
    "  p & \\text{if } x = 1 \\\\\n",
    "  1 - p & \\text{if } x = 0\n",
    "\\end{cases}\n",
    "```\n",
    "\n",
    "where $0<p<1$ is called the Bernoulli parameter. For a Bernoulli random variable $X(\\Omega) \\in [0,1]$ the expectation is given by:\n",
    "\n",
    "```{math}\n",
    "\\mathbb{E}\\left[X\\right] = p\n",
    "```\n",
    "\n",
    "while the variance $\\text{Var}(X)$ is given by:\n",
    "\n",
    "```{math}\n",
    "\\text{Var}\\left[X\\right] = p(1-p)\n",
    "```\n",
    "````\n",
    "\n",
    "Bernoulli random variables, named after the Swiss mathematician [Jacob Bernoulli](https://en.wikipedia.org/wiki/Jacob_Bernoulli), have two states: either `1` or `0`. The probability of getting `1` is $p$, while the likelihood of getting a value of `0` is $1 − p$. Bernoulli random variables model many binary events: coin flips (H or T), binary bits (1 or 0), true or false, yes or no, present or absent, etc.\n",
    "\n",
    "```julia\n",
    "# load the distributions package, and some other stuff\n",
    "using Distributions\n",
    "using Statistics\n",
    "using PrettyTables\n",
    "\n",
    "# Details of Bernoulli distribution: \n",
    "# https://juliastats.org/Distributions.jl/stable/univariate/#Discrete-Distributions\n",
    "\n",
    "# setup constants -\n",
    "p = 0.64;\n",
    "number_of_samples = 100;\n",
    "\n",
    "# build a Bernoulli distribution\n",
    "d = Bernoulli(p)\n",
    "\n",
    "# sample (check expectation, and variance)\n",
    "samples = rand(d,number_of_samples);\n",
    "\n",
    "# build a table -\n",
    "data_for_table = Array{Any,2}(undef, 2, 3)\n",
    "table_header = [\"\", \"E(X)\", \"Var(X)\"]\n",
    "\n",
    "# row 1: model\n",
    "data_for_table[1,1] = \"model\"\n",
    "data_for_table[1,2] = mean(d);\n",
    "data_for_table[1,3] = var(d);\n",
    "\n",
    "# row 2: samples\n",
    "data_for_table[2,1] = \"samples\"\n",
    "data_for_table[2,2] = mean(samples);\n",
    "data_for_table[2,3] = var(samples);\n",
    "pretty_table(data_for_table, header=table_header);\n",
    "```\n",
    "\n",
    "#### Binomial random variable\n",
    "The binomial distribution is the probability of getting exactly $k$ successes in $n$ independent Bernoulli trials, e.g., the chance of getting four heads in 6 coin tosses ({prf:ref}`defn-pmf-binomial`):\n",
    "\n",
    "````{prf:definition} Binomial Random Variable\n",
    ":label: defn-pmf-binomial\n",
    "\n",
    "Suppose we perform repeated Bernoulli trials $X(\\Omega) \\in [0,1]^n$, i.e., $n$ trials of an independent binary experiment. The probability of getting exactly $k$ successes in $n$ independent Bernoulli trials is governed by the binomial probability mass function:\n",
    "\n",
    "$$p_{X}(k) = \\binom{n}{k}p^{k}\\left(1-p\\right)^{n-k}\\qquad{k=0,1,\\dots,n}$$\n",
    "\n",
    "where $k$ denotes the number of successes in $n$ independent experiments, the binomial parameter $0<p<1$ is the probability \n",
    "of a successful trial and:\n",
    "\n",
    "$$\\binom{n}{k} = \\frac{n!}{k!\\left(n-k\\right)!}$$\n",
    "\n",
    "is the binomial coefficient. The expectation of a binomial random variable is given by:\n",
    "\n",
    "```{math}\n",
    "\\mathbb{E}\\left[X\\right] = np\n",
    "```\n",
    "\n",
    "while the variance $\\text{Var}(X)$ is given by:\n",
    "\n",
    "```{math}\n",
    "\\text{Var}\\left[X\\right] = np(1-p)\n",
    "```\n",
    "````\n",
    "\n",
    "```julia\n",
    "# load the distributions package, and some other stuff\n",
    "using Distributions\n",
    "using Statistics\n",
    "using PrettyTables\n",
    "\n",
    "# Details of Binomial distribution: \n",
    "# https://juliastats.org/Distributions.jl/stable/univariate/#Distributions.Binomial\n",
    "\n",
    "# setup constants -\n",
    "number_of_trials = 100;\n",
    "p = 0.64;\n",
    "number_of_samples = 100;\n",
    "\n",
    "# build a Bernoulli distribution\n",
    "d = Binomial(number_of_trials,p)\n",
    "\n",
    "# sample (check expectation, and variance)\n",
    "samples = rand(d,number_of_samples);\n",
    "\n",
    "# build a table -\n",
    "data_for_table = Array{Any,2}(undef, 2, 3)\n",
    "table_header = [\"\", \"E(X)\", \"Var(X)\"]\n",
    "\n",
    "# row 1: model\n",
    "data_for_table[1,1] = \"model\"\n",
    "data_for_table[1,2] = mean(d);\n",
    "data_for_table[1,3] = var(d);\n",
    "\n",
    "# row 2: samples\n",
    "data_for_table[2,1] = \"samples\"\n",
    "data_for_table[2,2] = mean(samples);\n",
    "data_for_table[2,3] = var(samples);\n",
    "pretty_table(data_for_table, header=table_header);\n",
    "```\n",
    "\n",
    "##### Geometric random variable\n",
    "Geometric random variables are a type of discrete probability distribution that models the number of trials required to obtain the first success in a sequence of independent Bernoulli trials ({prf:ref}`defn-pmf-geometric`):\n",
    "\n",
    "````{prf:definition} Geometric Random Variable\n",
    ":label: defn-pmf-geometric\n",
    "\n",
    "Let $X$ be a geometric random variable. The probability mass function for a geometric random variable is given by:\n",
    "\n",
    "$$p_{X}(k) = (1-p)^{(k-1)}p\\qquad{k=1,2,\\dots}$$\n",
    "\n",
    "where $p$ denotes the geometric parameter $0<p<1$. The expectation of a geometric random variable $X$ is given by:\n",
    "\n",
    "```{math}\n",
    "\\mathbb{E}\\left[X\\right] = \\frac{1}{p}\n",
    "```\n",
    "\n",
    "while the variance $\\text{Var}(X)$ is given by:\n",
    "\n",
    "```{math}\n",
    "\\text{Var}\\left[X\\right] = \\frac{1-p}{p^2}\n",
    "```\n",
    "````\n",
    "\n",
    "##### Poisson random variable\n",
    "Poisson random variables are a type of discrete probability distribution that models the number of occurrences of an event in a fixed interval of time or space ({prf:ref}`defn-pmf-poisson`): \n",
    "\n",
    "````{prf:definition} Poisson Random Variable\n",
    ":label: defn-pmf-poisson\n",
    "\n",
    "Let $X$ be a Poisson random variable. The probability mass function for a Poisson random variable is given by:\n",
    "\n",
    "```{math}\n",
    "p_{X}(x) = \\frac{\\lambda^{x}}{x!}\\exp\\left(-\\lambda\\right)\n",
    "```\n",
    "\n",
    "where $\\lambda>0$ denotes the Poisson parameter, and $!$ denotes the factorial function. The expectation of a Poisson random variable $X$ is given by:\n",
    "\n",
    "```{math}\n",
    "\\mathbb{E}\\left[X\\right] = \\lambda\n",
    "```\n",
    "\n",
    "while the variance $\\text{Var}(X)$ is given by:\n",
    "\n",
    "```{math}\n",
    "\\text{Var}\\left[X\\right] = \\lambda\n",
    "```\n",
    "````\n",
    "\n",
    "Poisson random variables estimate how likely something will happen $x$ number of times in a fixed interval, e.g., the number of car crashes in a city of a given size or the number of cheeseburgers sold at a fast-food chain on a Friday night.\n",
    "\n",
    "#### Expectation\n",
    "The [expectation](https://en.wikipedia.org/wiki/Expected_value) of a discrete random variable $X$ measures the central tendency of the values of that random variable ({prf:ref}`defn-discrete-random-variable-expectation`):\n",
    "\n",
    "````{prf:definition} Expectation discrete random variable\n",
    ":label: defn-discrete-random-variable-expectation\n",
    "\n",
    "Let $X$ denote a discere random variable with the probability space $\\left(\\Omega,\\mathcal{F},P\\right)$, where $\\Omega$ denotes the sample space, $\\mathcal{F}$ denotes the event space, and $P$ denotes the probability measure. Then, the expected value of the random variable $X$ is given by:\n",
    "\n",
    "```{math}\n",
    ":label: eqn-expectation\n",
    "\\mathbb{E}\\left[X\\right] = \\sum_{x\\in\\Omega}xp_{X}(x)\n",
    "```\n",
    "\n",
    "where $x$ denotes a value for the discrete random variable $X$, and $p_{X}(x)$ denotes the probability of $X=x$. The value of $p_{X}(x)$ is governed by a [Probability Mass Function (PMF)](https://en.wikipedia.org/wiki/Probability_mass_function).\n",
    "\n",
    "````\n",
    "\n",
    "The expectation of a discrete random variable has a few interesting properties ({prf:ref}`obs-expectation-props`):\n",
    "\n",
    "````{prf:observation} Properties of expectation\n",
    ":label: obs-expectation-props\n",
    "The expectation of a random variable $X$ has several useful (and important) properties: \n",
    "1. $\\mathbb{E}\\left(c\\right) = c$ for any constant $c$\n",
    "1. $\\mathbb{E}\\left(cX\\right) = c\\times\\mathbb{E}\\left(X\\right)$ for any constant $c$\n",
    "1. $\\mathbb{E}\\left(g(X)\\right) = \\sum_{x\\in{X(\\Omega)}}g(x)p_{X}(x)$\n",
    "1. $\\mathbb{E}\\left(g(X)+h(X)\\right) = \\mathbb{E}(g(X)) + \\mathbb{E}(h(X))$\n",
    "1. $\\mathbb{E}\\left(X+c\\right) = \\mathbb{E}(X) + c$ for any constant $c$\n",
    "````\n",
    "\n",
    "#### Variance\n",
    "The [variance](https://en.wikipedia.org/wiki/Variance) measures the expected dispersion for\n",
    "individual values of a random variable $X$, i.e., the average distance that values of $X$ are spread out from their expected value ({prf:ref}`defn-discrete-random-variable-variance`):\n",
    "\n",
    "````{prf:definition} Expectation discrete random variable\n",
    ":label: defn-discrete-random-variable-variance\n",
    "\n",
    "Let $X$ denote a discrete random variable with the probability space $\\left(\\Omega,\\mathcal{F},P\\right)$, where $\\Omega$ denotes the sample space, $\\mathcal{F}$ denotes the event space, and $P$ denotes the probability measure. Then, the variance of the random variable $X$ is given by:\n",
    "\n",
    "```{math}\n",
    ":label: eqn-variance\n",
    "\\text{Var}(X) = \\mathbb{E}\\Bigl[(X-\\mu)^{2}\\Bigr]\n",
    "```\n",
    "\n",
    "where $\\mu = \\mathbb{E}(X)$ denotes the expected value of the random variable $X$.\n",
    "\n",
    "````\n",
    "\n",
    "The variance of a discrete random variable has a few interesting properties ({prf:ref}`obs-variances-var`):\n",
    "\n",
    "````{prf:observation} Properties of variance\n",
    ":label: obs-variances-var\n",
    "\n",
    "The variance of a random variable $X$ has a few interesting (and important) properties:\n",
    "\n",
    "* $\\text{Var}(X) = \\mathbb{E}\\left(X^{2}\\right) - \\mathbb{E}\\left(X\\right)^2$\n",
    "* $\\text{Var}(cX) = {c^2}\\text{Var}(X)$ for any constant $c$\n",
    "* $\\text{Var}(X+c) = \\text{Var}(X)$ for any constant $c$\n",
    "\n",
    "````\n",
    "\n",
    "The more common quantity that is used to measure dispersion, the standard deviation $\\sigma$, is related to the variance: $\\sigma_{X} = \\sqrt{\\text{Var}(X)}$.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "# Summary\n",
    "Uncertain decisions are those that involve risk or ambiguity. Uncertain decisions arise in many situations, such as investing in the stock market, choosing a career path, making technical choices, or deciding whether to pursue a romantic relationship. \n",
    "\n",
    "In this lecture, we introduced tools to model and analyze simple uncertain decisions:\n",
    "\n",
    "* {ref}`content:references:utility-and-utlity-max` is the process of selecting the option that provides the highest level of satisfaction, or utility, based on the individual's preferences and constraints. This concept is often used in economics to model consumer behavior and in decision theory to analyze choices under uncertainty.\n",
    "\n",
    "* {ref}`content:references:utility-and-uncetain-decisions` are decision-making situations where the outcomes of different options are unknown or uncertain. These types of decisions often involve risk and involve balancing the potential rewards and risks of different options. To make optimal choices under uncertainty, decision-makers may use probabilistic tools such as expected utility theory to analyze the expected outcomes of different options."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst"
   }
  },
  "kernelspec": {
   "display_name": "Julia",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  },
  "source_map": [
   11
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}