
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Dynamic Progamming and Heuristic Optimization &#8212; CHEME 1800/4800</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="canonical" href="https://varnerlab.github.io/CHEME-1800-Computing-Book/landing.html/unit-3-learning/combitorial.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="The Decision Problem: Probability, Random Processes, and Decisions" href="../unit-4-decisions/decisions-landing.html" />
    <link rel="prev" title="Linear Programming" href="lp.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-VQRVBL1C02"></script>
<script>
                    window.dataLayer = window.dataLayer || [];
                    function gtag(){ dataLayer.push(arguments); }
                    gtag('js', new Date());
                    gtag('config', 'G-VQRVBL1C02');
                </script>

  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/cornell_seal_simple_black.svg" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">CHEME 1800/4800</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../landing.html">
                    Principles of Computational Thinking for Engineers
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../unit-1-basics/basics-landing.html">
   Unit 1. Basics
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../unit-1-basics/types.html">
     Expressions, Variables and Types
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../unit-1-basics/functions.html">
     Functions, Control Statements, and Recursion
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../unit-1-basics/programs.html">
     Programs and Modules
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../unit-1-basics/data-file-io.html">
     Data Input and Output
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../unit-2-data/data-landing.html">
   Unit 2. Data
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../unit-2-data/trees.html">
     Data Structures
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../unit-2-data/vectors-matricies-nla.html">
     Vectors, Matrices and Linear Algebraic Equations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../unit-2-data/reduction.html">
     Dimensionality Reduction
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="learning-landing.html">
   Unit 3. Learning
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="penalty.html">
     Ordinary Least Squares Problems
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="lp.html">
     Linear Programming
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Dynamic Progamming and Heuristic Optimization
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../unit-4-decisions/decisions-landing.html">
   Unit 4. Decisions
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../unit-4-decisions/simple.html">
     Probability and Simple Decisions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../unit-4-decisions/mdp.html">
     Markov Decision Processes
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../unit-4-decisions/multi-arm-bandits.html">
     Multiple Arm Bandit Problems and Reinforcement Learning
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../References.html">
   References
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/varnerlab/CHEME-1800-Computing-Book"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/varnerlab/CHEME-1800-Computing-Book/issues/new?title=Issue%20on%20page%20%2Funit-3-learning/combitorial.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/unit-3-learning/combitorial.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.md</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#introduction">
   Introduction
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#dynamic-programming">
   Dynamic programming
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#dynamic-decision-problems">
     Dynamic decision problems
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#heuristic-optimization">
   Heuristic optimization
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#simulated-annealing">
     Simulated annealing
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#summary">
   Summary
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Dynamic Progamming and Heuristic Optimization</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#introduction">
   Introduction
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#dynamic-programming">
   Dynamic programming
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#dynamic-decision-problems">
     Dynamic decision problems
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#heuristic-optimization">
   Heuristic optimization
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#simulated-annealing">
     Simulated annealing
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#summary">
   Summary
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="dynamic-progamming-and-heuristic-optimization">
<h1>Dynamic Progamming and Heuristic Optimization<a class="headerlink" href="#dynamic-progamming-and-heuristic-optimization" title="Permalink to this headline">#</a></h1>
<section id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">#</a></h2>
<p>Dynamic programming, heuristic optimization, and combinatorial optimization are all techniques used to solve optimization problems. In this lecture, we’ll introduce the following:</p>
<!-- Dynamic programming is a method that solves problems by breaking them down into smaller subproblems and solving them independently, then combining the solutions to the subproblems to solve the original problem. On the other hand, heuristic optimization algorithms are a family of algorithms inspired by natural phenomena and human behavior. They explore the search space using rules of thumb, intuition, and trial-and-error methods to find the best solution to a problem. Finally, combinatorial optimization is a field that deals with discrete optimization problems, where the search space consists of discrete objects or structures. There are many different approaches to solving these optimization problems, including exact algorithms, approximation algorithms, and heuristics. -->
<ul class="simple">
<li><p><a class="reference internal" href="#content-references-dynamic-programming"><span class="std std-ref">Dynamic programming</span></a> solves optimization problems by breaking them down into smaller subproblems, solving each subproblem once, and storing the solutions in a table or array. It is typically used for problems that can be divided into similar subproblems and for which the optimal solution can be constructed from optimal solutions to the subproblems.</p></li>
<li><p><a class="reference internal" href="#content-references-heuristic-optimization"><span class="std std-ref">Heuristic optimization</span></a> is a class of algorithms used to solve complex optimization problems inspired by natural phenomena, or human, insect or animal behavior.</p></li>
</ul>
<!-- * {ref}`content:references:branch-and-bound` is an algorithmic technique for solving combinatorial optimization problems. It involves dividing the search space into smaller subproblems and then using bounds on the optimal solutions to prune the search space and avoid considering suboptimal solutions. -->
<hr class="docutils" />
</section>
<section id="dynamic-programming">
<span id="content-references-dynamic-programming"></span><h2>Dynamic programming<a class="headerlink" href="#dynamic-programming" title="Permalink to this headline">#</a></h2>
<p>Dynamic programming is an approach developed by <a class="reference external" href="https://en.wikipedia.org/wiki/Richard_E._Bellman">Richard Bellman in the 1950s</a> that solves problems by breaking them down into smaller subproblems and storing the solutions to these subproblems. This allows the program to avoid recomputing the solution to the same subproblem multiple times and instead reuse the stored solutions, which can significantly improve the algorithm’s efficiency.</p>
<p>Dynamic programming is typically used for problems that can be divided into <a class="reference external" href="https://en.wikipedia.org/wiki/Overlapping_subproblems">overlapping subproblems</a>, i.e., the solution to one subproblem can be used to solve other subproblems. This is often the case with optimization problems, where the goal is to find the optimal solution among a set of possible solutions. It is also true for <em>sequential decision problems</em>.</p>
<section id="dynamic-decision-problems">
<h3>Dynamic decision problems<a class="headerlink" href="#dynamic-decision-problems" title="Permalink to this headline">#</a></h3>
<p>Imagine we have a decision-making agent in some state <span class="math notranslate nohighlight">\(x_{t}\)</span>, at time <span class="math notranslate nohighlight">\(t\)</span>. At time <span class="math notranslate nohighlight">\(t\)</span>, the agent takes an action <span class="math notranslate nohighlight">\(a_{t}\)</span> from a set of possible actions <span class="math notranslate nohighlight">\(a_{t}\in\mathcal{A}\left(x_{t}\right)\)</span> that leads to a new state <span class="math notranslate nohighlight">\(x_{t+1} = T(x_{t},a_{t})\)</span> and a payoff <span class="math notranslate nohighlight">\(F(x_{t},a_{t})\)</span>. In this situation, an infinite-horizon decision problem takes the form:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{eqnarray}
V(x_{\circ}) &amp; = &amp; \max_{a\in\mathcal{A}} \sum_{t=0}^{\infty}
\beta^{t}F(x_{t},a_{t}) \\
\text{subject to}&amp;~&amp; a_{t}\in\mathcal{A}(x_{t}) \\
\text{and} &amp;~&amp; x_{t+1} = T(x_{t},a_{t})
\end{eqnarray}
\end{split}\]</div>
<p>where the function <span class="math notranslate nohighlight">\(V(x_{\circ})\)</span> is the <em>value function</em>, <span class="math notranslate nohighlight">\(x_{\circ}\)</span> is the initial state of the agent and <span class="math notranslate nohighlight">\(0\leq\beta\leq{1}\)</span> denotes the discount factor.
Dynamic programming breaks this decision problem into smaller subproblems using Bellman’s principle of optimality (<a class="reference internal" href="#obs-bellman-principle-of-optimality">Observation 9</a>):</p>
<div class="proof observation admonition" id="obs-bellman-principle-of-optimality">
<p class="admonition-title"><span class="caption-number">Observation 9 </span> (Bellman’s principle of optimality)</p>
<section class="observation-content" id="proof-content">
<p><strong>Principle of optimality</strong>: An optimal policy has the property that whatever the initial state and initial decision are, the remaining decisions must constitute an optimal policy with regard to the state resulting from the first decision.</p>
</section>
</div><p>The optimality principle suggests that we can pull the first decision from the sum, which gives a value function of the form:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{eqnarray}
V(x_{\circ}) &amp; = &amp; \max_{a_{\circ}\in\mathcal{A}} \left\{F(x_{\circ},a_{\circ}) + \beta\cdot\left[\max_{a_{t}\mathcal{A}}\sum_{t=1}^{\infty}\beta^{t-1}F(x_{t},a_{t})\right]\right\}\\
\text{subject to}&amp;~&amp; a_{t}\in\mathcal{A}(x_{t}) \\
\text{and} &amp;~&amp; x_{t+1} = T(x_{t},a_{t})
\end{eqnarray}
\end{split}\]</div>
<p>However, the quantity inside the brackets of the <span class="math notranslate nohighlight">\(V(x_{\circ})\)</span> expression is just <span class="math notranslate nohighlight">\(V(x_{1})\)</span>, i.e., the decision problem starting at time step <code class="docutils literal notranslate"><span class="pre">1</span></code> instead of time step <code class="docutils literal notranslate"><span class="pre">0</span></code>. Thus, we can re-write the expression above as:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{eqnarray}
V(x_{\circ}) &amp; = &amp; \max_{a_{\circ}\in\mathcal{A}} \left\{F(x_{\circ},a_{\circ}) + \beta\cdot{V(x_{1})}\right\}\\
\text{subject to}&amp;~&amp; a_{t}\in\mathcal{A}(x_{t}) \\
\text{and} &amp;~&amp; x_{t+1} = T(x_{t},a_{t})
\end{eqnarray}
\end{split}\]</div>
<p>Dropping the subscripts gives rise to a <a class="reference external" href="https://en.wikipedia.org/wiki/Bellman_equation">Bellman equation</a> of the form shown in <a class="reference internal" href="#defn-bellman-decision-eqn">Definition 44</a>:</p>
<div class="proof definition admonition" id="defn-bellman-decision-eqn">
<p class="admonition-title"><span class="caption-number">Definition 44 </span> (Bellman equation)</p>
<section class="definition-content" id="proof-content">
<p>The optimal value of a state <span class="math notranslate nohighlight">\(x\)</span>, denoted by <span class="math notranslate nohighlight">\(V(x)\)</span>, is governed by a Bellman equation of the form:</p>
<div class="math notranslate nohighlight" id="equation-eqn-bellman-decision-eqn">
<span class="eqno">(81)<a class="headerlink" href="#equation-eqn-bellman-decision-eqn" title="Permalink to this equation">#</a></span>\[V(x) = \max_{a\in\mathcal{A}} \left\{F(x,a) + \beta\cdot{V(T(x,a))}\right\}\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathcal{A}\)</span> denotes the set of possible actions open to the decision maker and <span class="math notranslate nohighlight">\(0\leq\beta\leq{1}\)</span> represents the discount factor.</p>
</section>
</div><p>Equation <a class="reference internal" href="#equation-eqn-bellman-decision-eqn">(81)</a> is a <a class="reference external" href="https://en.wikipedia.org/wiki/Functional_equation">functional equation</a>, i.e., an equation in which functions appear as unknowns. Thus, solving Eqn. <a class="reference internal" href="#equation-eqn-bellman-decision-eqn">(81)</a> gives the unknown value function <span class="math notranslate nohighlight">\(V(x)\)</span>. Further, by calculating the value function, we will also find the <em>policy function</em> <span class="math notranslate nohighlight">\(a(x)\)</span> that describes the optimal action as a function of the system state <span class="math notranslate nohighlight">\(x\)</span>.</p>
</section>
</section>
<section id="heuristic-optimization">
<span id="content-references-heuristic-optimization"></span><h2>Heuristic optimization<a class="headerlink" href="#heuristic-optimization" title="Permalink to this headline">#</a></h2>
<p>Heuristic optimization is a family of algorithms inspired by natural phenomena and human behavior. Heuristic methods are often used to solve complex, real-world problems where exact solutions are difficult to obtain or may not even exist. Unlike traditional optimization methods, heuristic approaches use rules of thumb, intuition, and trial-and-error to explore the search space and find the best solution.</p>
<p>There are several types of heuristic optimization algorithms, including:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Simulated_annealing">Simulated Annealing (SA)</a> is inspired by the process of annealing in metallurgy. It starts with an initial solution and gradually changes it by randomly perturbing it and accepting or rejecting the new solution based on a probability function. SA is commonly used for problems that involve finding the global minimum of a non-convex function.</p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Genetic_algorithm">Genetic Algorithms (GA)</a> are inspired by the process of natural selection in biology. It starts with a population of potential solutions represented as chromosomes, which evolve through a series of selection, crossover, and mutation operations to create a new generation of solutions. GA is commonly used for problems that involve a large number of variables and constraints.</p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Particle_swarm_optimization">Particle Swarm Optimization (PSO)</a> simulates the behavior of a swarm of particles moving in a multi-dimensional search space. Each particle represents a potential solution to the problem, and it adjusts its position and velocity based on the best solution found by the swarm. PSO is commonly used for problems that require continuous optimization.</p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Ant_colony_optimization_algorithms">Ant Colony Optimization (ACO)</a> is inspired by the behavior of ant colonies. It involves a set of artificial ants that communicate with each other using pheromone trails to find the best path between a start and end point. ACO is commonly used for problems that find the shortest path in a graph.</p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Artificial_bee_colony_algorithm">Artificial Bee Colony (ABC)</a> simulates the behavior of a colony of artificial honey bees. ABC is commonly used for problems that involve finding the optimal solution in a continuous search space. Each bee represents a potential solution to the problem and adjusts its position based on the quality of the nectar source it has found.</p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Tabu_search">Tabu Search (TS)</a> uses a memory-based search strategy to avoid revisiting previously explored solutions. TS is commonly used for problems that involve finding the optimal solution in a combinatorial search space. It maintains a list of tabu moves, which are forbidden moves, to ensure that the search space is explored efficiently.</p></li>
</ul>
<section id="simulated-annealing">
<h3>Simulated annealing<a class="headerlink" href="#simulated-annealing" title="Permalink to this headline">#</a></h3>
<p>Simulated annealing (SA) is a heuristic optimization algorithm inspired by the annealing process in metallurgy <span id="id1">[<a class="reference internal" href="../References.html#id2" title="S Kirkpatrick and M. P. Vecchi. Optimization by Simulated Annealing. Science, 1983.">Kirkpatrick and Vecchi, 1983</a>]</span>. Simulated annealing is especially good at finding near-optimal solutions to problems with many local optima.</p>
<p>Simulated annealing solves complex optimization problems by randomly selecting a candidate solution, and evaluating the fitness of this candidate compared to the current best solution. The candidate solution is accepted or rejected based on a probability function; candidate solutions far away from the best solution are less likely to be selected. However, the willingness of the simulated annealing algorithm to choose a candidate far away from the best solution changes over time; in the beginning, the SA algorithm is more willing to take a chance. However, as time progresses, the SA algorithm only bets on sure things, i.e., new solutions that are strictly better than the best solution found so far.</p>
<p>A pseudo-code implementation for a simulated annealing routine is given in <a class="reference internal" href="#algo-simulated-annealing">Algorithm 12</a>:</p>
<div class="proof algorithm dropdown admonition" id="algo-simulated-annealing">
<p class="admonition-title"><span class="caption-number">Algorithm 12 </span> (Simulated Annealing)</p>
<section class="algorithm-content" id="proof-content">
<p><strong>Inputs</strong> The objective function <span class="math notranslate nohighlight">\(f\)</span>, temperature, neighbor, and accept functions, initial guess <span class="math notranslate nohighlight">\(x_{\circ}\)</span>, initial temperature <span class="math notranslate nohighlight">\(T\)</span>, and max iterations <span class="math notranslate nohighlight">\(\mathcal{M}_{\infty}\)</span></p>
<p><strong>Outputs</strong> the <span class="math notranslate nohighlight">\(\min_{x}f(x)\)</span> and <span class="math notranslate nohighlight">\(\arg\min_{x}f(x)\)</span>.</p>
<p><strong>Initialize</strong></p>
<ol class="simple">
<li><p>Set best solution <span class="math notranslate nohighlight">\(\hat{x}\leftarrow{x}_{\circ}\)</span></p></li>
<li><p>Set initial temperature <span class="math notranslate nohighlight">\(T_{0}\leftarrow{T}\)</span></p></li>
</ol>
<p><strong>Main</strong></p>
<ol class="simple">
<li><p>for <span class="math notranslate nohighlight">\(i\in\left\{1,\dots,\mathcal{M}_{\infty}\right\}\)</span></p>
<ol class="simple">
<li><p>update temperature <span class="math notranslate nohighlight">\(T_{i}\leftarrow\text{temperature}(T_{i-1},i)\)</span></p></li>
<li><p>generate new solution <span class="math notranslate nohighlight">\(x^{\prime}\leftarrow\text{neighbor}(\hat{x})\)</span></p></li>
<li><p>compute objective function difference <span class="math notranslate nohighlight">\(\Delta_{i} = f(x^{\prime}) - f(\hat{x})\)</span></p></li>
<li><p>if <span class="math notranslate nohighlight">\(\text{accept}(\Delta_{i},T_{i}) = \text{true}\)</span></p>
<ol class="simple">
<li><p>update the current best solution <span class="math notranslate nohighlight">\({\hat{x}}\leftarrow{x}^{\prime}\)</span></p></li>
</ol>
</li>
</ol>
</li>
</ol>
<p><strong>Return</strong>
the tuple <span class="math notranslate nohighlight">\(f(\hat{x})\)</span> and <span class="math notranslate nohighlight">\(\hat{x}\)</span>.</p>
</section>
</div><p>The performance of simulated annealing depends upon the choice of the temperature, neighbor, and accept functions. Example pseudo code implementations for these functions is shown in <a class="reference internal" href="#algo-simulated-annealing-other-functions">Algorithm 13</a>:</p>
<div class="proof algorithm dropdown admonition" id="algo-simulated-annealing-other-functions">
<p class="admonition-title"><span class="caption-number">Algorithm 13 </span> (Temperature, neighbor, and accept functions)</p>
<section class="algorithm-content" id="proof-content">
<p><strong>Temperature function</strong></p>
<ol class="simple">
<li><p>function temperature(<span class="math notranslate nohighlight">\(T\)</span>, <span class="math notranslate nohighlight">\(i\)</span>):</p>
<ol class="simple">
<li><p>return <span class="math notranslate nohighlight">\(T\leftarrow\alpha\times{T}~\)</span> where <span class="math notranslate nohighlight">\(\alpha&lt;1\)</span></p></li>
</ol>
</li>
</ol>
<p><strong>Accept function</strong></p>
<ol class="simple">
<li><p>function accept(<span class="math notranslate nohighlight">\(\Delta\)</span>, <span class="math notranslate nohighlight">\(T\)</span>):</p>
<ol class="simple">
<li><p>if <span class="math notranslate nohighlight">\(\Delta &lt; 0\)</span>:</p>
<ol class="simple">
<li><p>return true</p></li>
</ol>
</li>
<li><p>if random(0, 1) &lt; <span class="math notranslate nohighlight">\(\exp\left(-\Delta/T\right)\)</span>:</p>
<ol class="simple">
<li><p>return true</p></li>
</ol>
</li>
</ol>
</li>
<li><p>return false</p></li>
</ol>
<p><strong>Neighbor function</strong></p>
<ol class="simple">
<li><p>function neighbor(solution):</p>
<ol class="simple">
<li><p>set new_solution <span class="math notranslate nohighlight">\(\leftarrow\)</span> copy(solution)</p></li>
<li><p>select random move</p></li>
<li><p>perform move on new_solution</p></li>
</ol>
</li>
<li><p>return new_solution</p></li>
</ol>
</section>
</div><p>Let’s explore the performance of a simulated annealing implementation in <a class="reference internal" href="#example-sa-impl-spehere-function">Example 26</a>:</p>
<div class="proof example dropdown admonition" id="example-sa-impl-spehere-function">
<p class="admonition-title"><span class="caption-number">Example 26 </span> (Minimization of the Sphere function)</p>
<section class="example-content" id="proof-content">
<p>Minimize the d-dimensional sphere function <span class="math notranslate nohighlight">\(f(x)\)</span>:</p>
<div class="math notranslate nohighlight">
\[f(x) = \sum_{i=1}^{d}x_{i}^{2}\]</div>
<p>subject to the bounds constraints <span class="math notranslate nohighlight">\(x_{i}\in\left[-5.12,5.12\right]\)</span> using simulated annealing.
The solution code for this example can be found <a class="reference external" href="https://github.com/varnerlab/CHEME-1800-4800-Course-Repository-S23/tree/main/examples/unit-3-examples/simulated_annealing">here</a>.</p>
</section>
</div><!-- ### Genetic algortihms

Genetic algorithms are heuristic optimization algorithms inspired by natural selection and genetic inheritance. Genetic algorithms solve problems by iteratively generating and evaluating a population of candidate solutions, then applying selection, crossover, and mutation operators to evolve the population toward better solutions.

Genetic algorithms can handle continuous and discrete search spaces and are often used in complex optimization problems such as scheduling, routing, and machine learning. A pseudocode implementation of a genetic algorithm is given in {prf:ref}`algo-genetic-algorithm`:

````{prf:algorithm} Genetic Algorithm
:label: algo-genetic-algorithm
:class: dropdown

**Initialize** 
1. set $\mathcal{P}\leftarrow\text{initialize_population()}$
1. set $\mathcal{F}\leftarrow\text{evaluate_fitness}(\mathcal{P})$

**Main**
1. while not termination_condition_met():
    1. set $x\leftarrow\text{select_parents()}$
    1. set $x^{\prime}\leftarrow\text{create_offspring}(x)$
    1. set $\mathcal{F}^{\prime}\leftarrow\text{evaluate_fitness}(x^{\prime})$
    1. replace_least_fit()

1. return_best()

**Initialize populattion**
// create population of individuals with random genes
1. function initialize_population():
    1. set population = []
    1. for $i\in {1,2,\dots,\text{population_size}}$:
        1. individual = create_random_individual()
        1. population.append(individual)

**Evaluate fitness**
// evaluate fitness of each individual in the population
1. function evaluate_fitness():
    1. for individual in population:
        1. set individual.fitness $\leftarrow$ calculate_fitness(individual)

**Select parents**
// select parents for reproduction
1. function select_parents():
    1. set parents $\leftarrow$ []
    1. for i $\in{1:\text{parent_selection_size}}$:
        1. set parent $\leftarrow$ tournament_selection(population, tournament_size)
        1. parents.append(parent)
1. return parents

**Create offspring**
// create offspring through crossover and mutation
1. function create_offspring():
    1. offspring $\leftarrow$ []
    1. for i in range(offspring_size):
        1. parent1, parent2 = select_parents()
        1. child = crossover(parent1, parent2)
        1. child = mutate(child)
        1. offspring.append(child)
    1. return offspring

**Replace**
// replace least fit individuals in the population with offspring
1. function replace_least_fit():
    1. set offspring_fitness = [individual.fitness for individual in offspring]
    1. for i in range(replacement_size):
        1. set least_fit_index $\leftarrow$ population_fitness.index(min(population_fitness))
        1. set population[least_fit_index] $\leftarrow$ offspring[i]
        1. set population_fitness[least_fit_index] $\leftarrow$ offspring_fitness[i]

**Best individual**
// return individual with best fitness
1. function return_best():
    1. set best_individual $\leftarrow$ max(population, key=lambda individual: individual.fitness)
1. return best_individual

**Tournament selection**
// select individual with highest fitness in tournament
1. function tournament_selection(population, tournament_size):
    1. set tournament $\leftarrow$ random.sample(population, tournament_size)
    1. set winner $\leftarrow$ max(tournament, key=lambda individual: individual.fitness)
1. return winner

**Crossover**
// combine genes of parents to create child
1. function crossover(parent1, parent2):
    1. set child $\leftarrow$ Individual()
    1. for i in range(gene_count):
        1. if random.random() < crossover_probability:
            1. child.genes[i] $\leftarrow$ parent1.genes[i]
        1. else:
            1. child.genes[i] $\leftarrow$ parent2.genes[i]
1. return child

**Mutate**
// randomly mutate genes of individual
1. function mutate(individual):
    1. for $i\in{1,2,\dots\text{gene_count}}$:
        1. if random.random() < mutation_probability:
            1. individual.genes[i] $\leftarrow\mathcal{U}$(min_gene_value, max_gene_value)
1. return individual
```` -->
<!-- 
While some problems cannot be decomposed in this way, problems that span several time points or naturally structured in stages can often be decomposed recursively. If a problem can be solved optimally by breaking it into subproblems and then recursively finding the optimal solutions to the subproblems, then it is said to have _optimal substructure_.

If dynamic programming methods are applicable, then there is a relationship between the value of the larger problem and the values of the subproblems; this relationship is called the [Bellman equation](https://en.wikipedia.org/wiki/Bellman_equation). 

Dynamic programming can be a valuable tool for solving many problems, but it can be computationally intensive and may only sometimes be the most efficient solution. When deciding whether to use dynamic programming, it is essential to consider the trade-offs between the algorithm’s efficiency and the problem’s complexity. -->
<!-- (content:references:branch-and-bound)=
## Branch and Bound

Branch and bound is an approach to solve a variety of discrete and combinatorial optimization problems. A branch-and-bound algorithm enumerates candidate solutions by means of state space search: the set of candidate solutions forms a rooted tree with the full set at the root.

Let's consider minimizing an arbitrary objective function $f$:

```{prf:algorithm} Branch and Bound Algorithm
:label: algo-branch-bound-generic
:class: dropdown

**Inputs** the objective function $f$, a branch function, and a bound function

**Outputs** the minimum function value $\mathcal{B}$

**Initialize** 
1. Set $\mathcal{B}\leftarrow\infty$ where $\mathcal{B}$ is the best solution found so far
2. Initialize $Q$, a queue holding problem variables

**Main**
1. while $Q$ is not empty
    1. Take a node $N$ from the queue: $N\leftarrow\text{dequeue}(Q)$
    1. Evaluate the objective function value of node $N$: $B_{N}\leftarrow{f(x_{N})}$  
    1. if $B_{N}<\mathcal{B}$
        1. Update best solution: $\mathcal{B}\leftarrow{B_{N}}$
    1. else
        1. Branch on node $N$ to produce new candidate nodes: $(N_{1},\dots) \leftarrow\text{branch}(N)$
        1. for N $\in\left(N_{1},\dots\right)$
            1. if bound(N) $\leq\mathcal{B}$
                1. Q $\leftarrow$ enqueue(Q, N)

**Return**
the minimum function value $\mathcal{B}$
``` -->
</section>
</section>
<hr class="docutils" />
<section id="summary">
<h2>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">#</a></h2>
<p>Dynamic programming, heuristic optimization, and other combinatorial optimization techniques can all be used to solve optimization problems.
In this lecture we introduced several optimization approaches:</p>
<!-- 
Dynamic programming is a method that solves problems by breaking them down into smaller subproblems and solving them independently, then combining the solutions to the subproblems to solve the original problem. On the other hand, heuristic optimization algorithms are a family of algorithms inspired by natural phenomena and human behavior. They explore the search space using rules of thumb, intuition, and trial-and-error methods to find the best solution to a problem. Finally, combinatorial optimization is a field that deals with discrete optimization problems, where the search space consists of discrete objects or structures. There are many different approaches to solving these optimization problems, including exact algorithms, approximation algorithms, and heuristics.

In this lecture we introduced several optimization approaches: -->
<ul class="simple">
<li><p><a class="reference internal" href="#content-references-dynamic-programming"><span class="std std-ref">Dynamic programming</span></a> solves optimization problems by breaking them down into smaller subproblems, solving each subproblem once, and storing the solutions in a table or array. It is typically used for problems that can be divided into similar subproblems and for which the optimal solution can be constructed from optimal solutions to the subproblems.</p></li>
<li><p><a class="reference internal" href="#content-references-heuristic-optimization"><span class="std std-ref">Heuristic optimization</span></a> is a class of algorithms used to solve complex optimization problems, inspired by natural phenomena and human behavior. These algorithms are particularly useful when mathematical models are not available or are too expensive to compute.</p></li>
</ul>
<!-- * {ref}`content:references:branch-and-bound` is an algorithmic technique for solving combinatorial optimization problems. It involves dividing the search space into smaller subproblems and then using bounds on the optimal solutions to prune the search space and avoid considering suboptimal solutions. -->
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./unit-3-learning"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="lp.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Linear Programming</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="../unit-4-decisions/decisions-landing.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">The Decision Problem: Probability, Random Processes, and Decisions</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Varner<br/>
  
      &copy; Copyright 2023.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>