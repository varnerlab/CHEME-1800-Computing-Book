
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Probability and Uncertain Choices &#8212; CHEME 1800/4800</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="canonical" href="https://varnerlab.github.io/CHEME-1800-Computing-Book/landing.html/unit-4-decisions/simple.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Markov Decision Processes" href="mdp.html" />
    <link rel="prev" title="The Decision Problem: Probability, Random Processes, and Decisions" href="decisions-landing.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-VQRVBL1C02"></script>
<script>
                    window.dataLayer = window.dataLayer || [];
                    function gtag(){ dataLayer.push(arguments); }
                    gtag('js', new Date());
                    gtag('config', 'G-VQRVBL1C02');
                </script>

  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/cornell_seal_simple_black.svg" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">CHEME 1800/4800</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../landing.html">
                    Principles of Computational Thinking for Engineers
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../unit-1-basics/basics-landing.html">
   Unit 1. Basics
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../unit-1-basics/types.html">
     Expressions, Variables and Types
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../unit-1-basics/functions.html">
     Functions, Control Statements, and Recursion
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../unit-1-basics/programs.html">
     Programs and Modules
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../unit-1-basics/data-file-io.html">
     Data Input and Output
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../unit-2-data/data-landing.html">
   Unit 2. Data
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../unit-2-data/trees.html">
     Data Structures
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../unit-2-data/vectors-matricies-nla.html">
     Vectors, Matrices and Linear Algebraic Equations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../unit-2-data/reduction.html">
     Dimensionality Reduction
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../unit-3-learning/learning-landing.html">
   Unit 3. Learning
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../unit-3-learning/penalty.html">
     Ordinary Least Squares Problems
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../unit-3-learning/lp.html">
     Linear Programming
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../unit-3-learning/combitorial.html">
     Dynamic Progamming and Heuristic Optimization
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="decisions-landing.html">
   Unit 4. Decisions
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Probability and Uncertain Choices
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="mdp.html">
     Markov Decision Processes
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="multi-arm-bandits.html">
     Multiple Arm Bandit Problems and Reinforcement Learning
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../References.html">
   References
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/varnerlab/CHEME-1800-Computing-Book/main?urlpath=tree/unit-4-decisions/simple.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/varnerlab/CHEME-1800-Computing-Book"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/varnerlab/CHEME-1800-Computing-Book/issues/new?title=Issue%20on%20page%20%2Funit-4-decisions/simple.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/unit-4-decisions/simple.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download notebook file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-code"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        <a href="../_sources/unit-4-decisions/simple.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.md</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Probability and Uncertain Choices
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#utility-maximization">
     Utility maximization
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#properties-of-utility-functions">
       Properties of utility functions
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#marginal-utility">
         Marginal utility
        </a>
        <ul class="nav section-nav flex-column">
         <li class="toc-h5 nav-item toc-entry">
          <a class="reference internal nav-link" href="#analytical-marginal-utility">
           Analytical marginal utility
          </a>
         </li>
         <li class="toc-h5 nav-item toc-entry">
          <a class="reference internal nav-link" href="#numerical-marginal-utility">
           Numerical marginal utility
          </a>
         </li>
         <li class="toc-h5 nav-item toc-entry">
          <a class="reference internal nav-link" href="#aside-marginal-utility-of-wealth">
           Aside: Marginal utility of wealth
          </a>
         </li>
        </ul>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#indifference-curves">
       Indifference curves
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#marginal-rate-of-substitution">
       Marginal rate of substitution
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#optimal-choices-and-budgets">
       Optimal choices and budgets
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#choices-under-uncertainty">
     Choices under uncertainty
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#the-von-neumann-morgenstern-theorem">
       The von Neumann - Morgenstern theorem
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#probability-mass-functions">
         Probability mass functions
        </a>
        <ul class="nav section-nav flex-column">
         <li class="toc-h5 nav-item toc-entry">
          <a class="reference internal nav-link" href="#bernoulli-random-variable">
           Bernoulli random variable
          </a>
         </li>
        </ul>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#binomial-random-variable">
         Binomial random variable
        </a>
        <ul class="nav section-nav flex-column">
         <li class="toc-h5 nav-item toc-entry">
          <a class="reference internal nav-link" href="#geometric-random-variable">
           Geometric random variable
          </a>
         </li>
         <li class="toc-h5 nav-item toc-entry">
          <a class="reference internal nav-link" href="#poisson-random-variable">
           Poisson random variable
          </a>
         </li>
        </ul>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#expectation">
         Expectation
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#variance">
         Variance
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#summary">
   Summary
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Probability and Uncertain Choices</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Probability and Uncertain Choices
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#utility-maximization">
     Utility maximization
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#properties-of-utility-functions">
       Properties of utility functions
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#marginal-utility">
         Marginal utility
        </a>
        <ul class="nav section-nav flex-column">
         <li class="toc-h5 nav-item toc-entry">
          <a class="reference internal nav-link" href="#analytical-marginal-utility">
           Analytical marginal utility
          </a>
         </li>
         <li class="toc-h5 nav-item toc-entry">
          <a class="reference internal nav-link" href="#numerical-marginal-utility">
           Numerical marginal utility
          </a>
         </li>
         <li class="toc-h5 nav-item toc-entry">
          <a class="reference internal nav-link" href="#aside-marginal-utility-of-wealth">
           Aside: Marginal utility of wealth
          </a>
         </li>
        </ul>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#indifference-curves">
       Indifference curves
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#marginal-rate-of-substitution">
       Marginal rate of substitution
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#optimal-choices-and-budgets">
       Optimal choices and budgets
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#choices-under-uncertainty">
     Choices under uncertainty
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#the-von-neumann-morgenstern-theorem">
       The von Neumann - Morgenstern theorem
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#probability-mass-functions">
         Probability mass functions
        </a>
        <ul class="nav section-nav flex-column">
         <li class="toc-h5 nav-item toc-entry">
          <a class="reference internal nav-link" href="#bernoulli-random-variable">
           Bernoulli random variable
          </a>
         </li>
        </ul>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#binomial-random-variable">
         Binomial random variable
        </a>
        <ul class="nav section-nav flex-column">
         <li class="toc-h5 nav-item toc-entry">
          <a class="reference internal nav-link" href="#geometric-random-variable">
           Geometric random variable
          </a>
         </li>
         <li class="toc-h5 nav-item toc-entry">
          <a class="reference internal nav-link" href="#poisson-random-variable">
           Poisson random variable
          </a>
         </li>
        </ul>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#expectation">
         Expectation
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#variance">
         Variance
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#summary">
   Summary
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="probability-and-uncertain-choices">
<h1>Probability and Uncertain Choices<a class="headerlink" href="#probability-and-uncertain-choices" title="Permalink to this headline">#</a></h1>
<p>Uncertain decisions are those that involve a certain degree of risk or ambiguity. Uncertain decisions arise in many situations, such as investing in the stock market, choosing a career path, making technical choices, or deciding whether to pursue a romantic relationship. Making uncertain decisions involves weighing each option’s potential benefits and drawbacks and considering the likelihood of different outcomes.</p>
<p>In this lecture, we introduce tools to model and analyze simple uncertain decisions:</p>
<ul class="simple">
<li><p><a class="reference internal" href="#content-references-utility-and-utlity-max"><span class="std std-ref">Utility maximization</span></a> is the process of selecting the option that provides the highest level of satisfaction, or utility, based on the individual’s preferences and constraints. This concept is often used in economics to model consumer behavior and in decision theory to analyze choices under uncertainty.</p></li>
<li><p><a class="reference internal" href="#content-references-utility-and-uncetain-decisions"><span class="std std-ref">Choices under uncertainty</span></a> are decision-making situations where the outcomes of different options are unknown or uncertain. These types of decisions often involve risk and involve balancing the potential rewards and risks of different options. To make optimal choices under uncertainty, decision-makers may use probabilistic tools such as expected utility theory to analyze the expected outcomes of different options.</p></li>
</ul>
<hr class="docutils" />
<section id="utility-maximization">
<span id="content-references-utility-and-utlity-max"></span><h2>Utility maximization<a class="headerlink" href="#utility-maximization" title="Permalink to this headline">#</a></h2>
<p>A utility function is a mathematical expression representing an individual’s preferences over different choices or outcomes. It assigns a numerical value, called <em>utility</em>, to each possible option based on how much the individual values it. A utility function is subjective and can vary from person to person, as different individuals may have other preferences.</p>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Rational_choice_theory">Rational choice theory</a> assumes individuals make rational decisions based on their preferences and available information. <a class="reference external" href="https://en.wikipedia.org/wiki/Rational_choice_theory">Rational choice theory</a> is based on computing the utility of actions or outcomes. Thus, utility functions are a crucial component of this theory, as they describe how individuals assign values to different results or choices (<a class="reference internal" href="#defn-individual-utility">Definition 45</a>):</p>
<div class="proof definition admonition" id="defn-individual-utility">
<p class="admonition-title"><span class="caption-number">Definition 45 </span> (Ordinal utility function)</p>
<section class="definition-content" id="proof-content">
<p>An individual decision-making agent is presented with a bundle of <span class="math notranslate nohighlight">\(n\)</span> objects <span class="math notranslate nohighlight">\(x_{1},\dots,x_{n}\)</span>. A utility function represents the preference of the agent for combinations of these <span class="math notranslate nohighlight">\(n\)</span> objects:</p>
<div class="math notranslate nohighlight" id="equation-eqn-utility-function-generic">
<span class="eqno">(82)<a class="headerlink" href="#equation-eqn-utility-function-generic" title="Permalink to this equation">#</a></span>\[U(x_{1},x_{2},\dots,x_{n})\]</div>
<p>The utility function <span class="math notranslate nohighlight">\(U(\dots)\)</span> is unique only up to an order-preserving transformation in period <span class="math notranslate nohighlight">\(t\rightarrow{t+dt}\)</span>. Further, utility functions are ordinal, i.e., they rank-order bundles but do not indicate how much better a bundle is compared to another.</p>
</section>
</div><p><a class="reference internal" href="#defn-individual-utility">Definition 45</a> does not give specifics about the properties of a utility function. However, it does establish a critical concept; the utility can be used to rank order the preference for different choices. For example, suppose we have two choices, <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(B\)</span>:</p>
<ul class="simple">
<li><p>If <span class="math notranslate nohighlight">\(A\succ{B}\)</span>, the decision maker <em>strictly prefers</em> <span class="math notranslate nohighlight">\(A\)</span> to <span class="math notranslate nohighlight">\(B\)</span>. Then, the utility of choice <span class="math notranslate nohighlight">\(A\)</span> is greater than <span class="math notranslate nohighlight">\(B\)</span>, or <span class="math notranslate nohighlight">\(U(A)&gt;U(B)\)</span>.</p></li>
<li><p>If <span class="math notranslate nohighlight">\(A\sim{B}\)</span>, the decision maker is <em>indifferent</em> between <span class="math notranslate nohighlight">\(A\)</span> to <span class="math notranslate nohighlight">\(B\)</span>. Then, the utility of choice <span class="math notranslate nohighlight">\(A\)</span> is the same as <span class="math notranslate nohighlight">\(B\)</span>, or <span class="math notranslate nohighlight">\(U(A)=U(B)\)</span>.</p></li>
<li><p>If <span class="math notranslate nohighlight">\(A\succsim{B}\)</span>, the decision maker <em>weakly prefers</em> <span class="math notranslate nohighlight">\(A\)</span> over <span class="math notranslate nohighlight">\(B\)</span>, or they are indifferent. Then, the utility of choice <span class="math notranslate nohighlight">\(A\)</span> is greater than or equal to <span class="math notranslate nohighlight">\(B\)</span>, or <span class="math notranslate nohighlight">\(U(A)\geq{U(A)}\)</span>.</p></li>
</ul>
<section id="properties-of-utility-functions">
<h3>Properties of utility functions<a class="headerlink" href="#properties-of-utility-functions" title="Permalink to this headline">#</a></h3>
<p>A utility function is a mathematical representation of a person’s preferences over different outcomes or alternatives. Here are some properties that a utility function should possess:</p>
<ul class="simple">
<li><p><strong>Completeness</strong>: A utility function should be able to rank all possible outcomes or alternatives. In other words, for any two outcomes, the utility function should tell us which one is preferred or whether they are equally preferred.</p></li>
<li><p><strong>Transitivity</strong>: If outcome A is preferred to outcome B, and outcome B is preferred to outcome C, then outcome A must be preferred to outcome C. This is known as the transitivity property.</p></li>
<li><p><strong>Monotonicity</strong>: If more of a good is always preferred to less, then the utility function should increase in that good. Conversely, if less of a bad is always preferred to more, then the utility function should decrease in that bad.</p></li>
<li><p><strong>Continuity</strong>: Small changes in the outcome or alternatives should result in small changes in the utility function. This is known as the continuity property.</p></li>
<li><p><strong>Concavity</strong>: The utility function should be concave if the person exhibits diminishing marginal utility. This means that as a person consumes more of a good, the additional satisfaction gained from each unit consumed decreases.</p></li>
</ul>
<p>These properties help ensure that a utility function accurately represents a person’s preferences and can be used to make rational choices between alternatives.</p>
<section id="marginal-utility">
<h4>Marginal utility<a class="headerlink" href="#marginal-utility" title="Permalink to this headline">#</a></h4>
<p>The marginal utility is the additional satisfaction or usefulness an agent derives from consuming one additional unit of a good or service. Mathematically, the marginal utility is the partial derivative of the utility with respect to the amount of item <span class="math notranslate nohighlight">\(i\)</span> (<a class="reference internal" href="#defn-marginal-utility-math">Definition 46</a>):</p>
<div class="proof definition admonition" id="defn-marginal-utility-math">
<p class="admonition-title"><span class="caption-number">Definition 46 </span> (Marginal utility)</p>
<section class="definition-content" id="proof-content">
<p>The preference or satisfaction derived from a bundle of objects <span class="math notranslate nohighlight">\(x_{1},\dots,x_{n}\)</span> is described by the utility function <span class="math notranslate nohighlight">\(U(x_{1},\dots,x_{n})\)</span>. Then, the satisfaction experienced by the agent from one additional unit of the object <span class="math notranslate nohighlight">\(i\)</span> in the bundle is defined as the marginal utility of object <span class="math notranslate nohighlight">\(i\)</span>:</p>
<div class="math notranslate nohighlight">
\[\text{MU}^{\star}_{i} \equiv \left(\frac{\partial{U}}{\partial{x_{i}}}\right)_{\star}\qquad{i=1,2,\dots,n}\]</div>
<p>where all other objects are held constant at level <span class="math notranslate nohighlight">\(\star\)</span>.</p>
</section>
</div><section id="analytical-marginal-utility">
<h5>Analytical marginal utility<a class="headerlink" href="#analytical-marginal-utility" title="Permalink to this headline">#</a></h5>
<p>The marginal utility can be computed by directly differentiating the utility function. For example, consider an example utility function that we’ll use later, the <a class="reference external" href="https://en.wikipedia.org/wiki/Cobb%E2%80%93Douglas_production_function">Cobb-Douglas utility function</a>. The <a class="reference external" href="https://en.wikipedia.org/wiki/Cobb%E2%80%93Douglas_production_function">Cobb–Douglas utility function</a> governing the satisfaction gained by consuming a bundle of <span class="math notranslate nohighlight">\(n\)</span> goods <span class="math notranslate nohighlight">\((x_{1},x_{2},\dots,x_{n})\)</span> is given by:</p>
<div class="math notranslate nohighlight" id="equation-eqn-cobb-douglas-u-function">
<span class="eqno">(83)<a class="headerlink" href="#equation-eqn-cobb-douglas-u-function" title="Permalink to this equation">#</a></span>\[U(x)  = \prod_{i=1}^{n}x_{i}^{\alpha_{i}} \]</div>
<p>where the coefficients <span class="math notranslate nohighlight">\(\alpha_{i}\)</span> are governed by:</p>
<div class="math notranslate nohighlight">
\[\sum_{i=1}^{n}\alpha_{i}  = 1\]</div>
<p>The <a class="reference external" href="https://en.wikipedia.org/wiki/Cobb%E2%80%93Douglas_production_function">Cobb–Douglas utility function</a> satisfies the utility function properties, where the marginal utility is given by:</p>
<div class="math notranslate nohighlight" id="equation-eqn-mu-u-function">
<span class="eqno">(84)<a class="headerlink" href="#equation-eqn-mu-u-function" title="Permalink to this equation">#</a></span>\[\text{MU}_{x_{i}} = \left(\alpha_{i}x^{\alpha_{i}-1}\right)\cdot\left(\prod_{j=1,i}^{n}x_{j}^{\alpha_{j}}\right)\]</div>
<p>where the <span class="math notranslate nohighlight">\(j=1,i\)</span> notation denotes the <em>exclusion</em> of index <span class="math notranslate nohighlight">\(i\)</span>. As <span class="math notranslate nohighlight">\(x_{i}\rightarrow\infty\)</span>, the marginal utility <span class="math notranslate nohighlight">\(\text{MU}_{x_{i}}\rightarrow{0}\)</span> if <span class="math notranslate nohighlight">\(\alpha_{i}&lt;1\)</span>. Thus, the convexity property is satisfied for <span class="math notranslate nohighlight">\(\alpha_{i}&lt;1\)</span>. Alternatively, to compute analytical expressions for the marginal utility, instead of remembering the <a class="reference external" href="https://en.wikipedia.org/wiki/Differentiation_rules">differentiation rules from calculus</a>, we can use one of many <a class="reference external" href="https://en.wikipedia.org/wiki/Computer_algebra_system">Computer Algebra Systems (CAS)</a>, e.g., the <a class="reference external" href="https://github.com/JuliaSymbolics/Symbolics.jl">Symbolics.jl</a> package in <a class="reference external" href="https://julialang.org">Julia</a> or the <a class="reference external" href="https://www.sympy.org/en/index.html">SymPy</a> library in <a class="reference external" href="https://www.python.org">Python</a>.</p>
<p>Sample code to compute the marginal utility for the two-dimensional <a class="reference external" href="https://en.wikipedia.org/wiki/Cobb%E2%80%93Douglas_production_function">Cobb-Douglas utility function</a> using the <a class="reference external" href="https://github.com/JuliaSymbolics/Symbolics.jl">Symbolics.jl</a> package:</p>
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="c"># load the Symbolics.jl package (assumed to be installed)</span>
<span class="k">using</span> <span class="n">Symbolics</span>

<span class="c"># declare variables (symbols in the eqn)</span>
<span class="nd">@variables</span> <span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">α</span><span class="p">,</span><span class="n">β</span>

<span class="c"># Build differential operators for x</span>
<span class="n">Dₓ</span> <span class="o">=</span> <span class="n">Differential</span><span class="p">(</span><span class="n">x</span><span class="p">);</span>

<span class="c"># define the utility function</span>
<span class="n">U</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span><span class="o">^</span><span class="n">α</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="n">y</span><span class="o">^</span><span class="n">β</span><span class="p">)</span>

<span class="c"># compute the derivative -</span>
<span class="n">∂Uₓ</span> <span class="o">=</span> <span class="n">Dₓ</span><span class="p">(</span><span class="n">U</span><span class="p">)</span> <span class="o">|&gt;</span> <span class="n">expand_derivatives</span><span class="p">;</span>

<span class="c"># print -</span>
<span class="n">println</span><span class="p">(</span><span class="s">&quot;The value of ∂U/∂x = &quot;</span><span class="p">,</span><span class="n">∂Uₓ</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="numerical-marginal-utility">
<h5>Numerical marginal utility<a class="headerlink" href="#numerical-marginal-utility" title="Permalink to this headline">#</a></h5>
<p>However, sometimes it may not be convenient to analytically compute the derivative, e.g., the utility function is complicated. You can always approximate the marginal utility using a <a class="reference external" href="https://en.wikipedia.org/wiki/Finite_difference">finite difference approximation</a>, or <a class="reference external" href="https://en.wikipedia.org/wiki/Automatic_differentiation">automatic differentiation</a> approach.</p>
<p>Sample code for <a class="reference external" href="https://en.wikipedia.org/wiki/Automatic_differentiation">automatic differentiation</a> of the Cobb-Douglas utility function using the <a class="reference external" href="https://juliadiff.org/ForwardDiff.jl/stable/">ForwardDiff.jl</a> package:</p>
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="c"># load the ForwardDiff package</span>
<span class="k">using</span> <span class="n">ForwardDiff</span>

<span class="c"># Cobb-Douglas utility function</span>
<span class="k">function</span> <span class="n">U</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="c"># initialize</span>
    <span class="n">α₁</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">;</span>
    <span class="n">α₂</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">α₁</span>
    
    <span class="c"># return</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">^</span><span class="n">α₁</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">^</span><span class="n">α₂</span><span class="p">)</span>
<span class="k">end</span>

<span class="c"># Estimate the MU -</span>
<span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="mf">20.0</span><span class="p">,</span><span class="mf">7.20</span><span class="p">];</span> <span class="c"># point A </span>
<span class="n">MU</span> <span class="o">=</span> <span class="n">ForwardDiff</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">U</span><span class="p">,</span><span class="n">x</span><span class="p">);</span>
</pre></div>
</div>
</section>
<section id="aside-marginal-utility-of-wealth">
<h5>Aside: Marginal utility of wealth<a class="headerlink" href="#aside-marginal-utility-of-wealth" title="Permalink to this headline">#</a></h5>
<p>The marginal utility quantifies the satisfaction gained by an agent from an additional unit of consumption of a good or service (<a class="reference internal" href="#fig-wealth-schematic-simple-model"><span class="std std-numref">Fig. 16</span></a>).</p>
<figure class="align-default" id="fig-wealth-schematic-simple-model">
<a class="reference internal image-reference" href="../_images/Fig-Wealth-Utility-Schematic.pdf"><img alt="../_images/Fig-Wealth-Utility-Schematic.pdf" src="../_images/Fig-Wealth-Utility-Schematic.pdf" style="height: 400px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 16 </span><span class="caption-text">Wealth utility function <span class="math notranslate nohighlight">\(U(W) = W/(W+b)\)</span> as a function of choices for the parameter <span class="math notranslate nohighlight">\(b\)</span>. The abundance of wealth is inversely proportional to the value of the parameter <span class="math notranslate nohighlight">\(b\)</span>. For example, the agent at <span class="math notranslate nohighlight">\(A\)</span> values each additional wealth unit less than the agent at <span class="math notranslate nohighlight">\(D\)</span>.</span><a class="headerlink" href="#fig-wealth-schematic-simple-model" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>The relationship between overall resource level (wealth) and the marginal utility of resources is a fundamental concept in economics that explains how individuals value resources and other material possessions. Marginal utility is basic to how an agent values a good or service, including wealth. According to this concept, the more wealth a person has, the less value each additional unit of wealth provides in terms of satisfaction or well-being. This is because as a person’s wealth increases, the marginal utility of each additional wealth unit decreases due to the <a class="reference external" href="https://en.wikipedia.org/wiki/Marginal_utility">diminishing marginal utility of money</a>.</p>
</section>
</section>
</section>
<section id="indifference-curves">
<h3>Indifference curves<a class="headerlink" href="#indifference-curves" title="Permalink to this headline">#</a></h3>
<p>Indifference curves are graphical representations of combinations of choices that provide a decision-making agent with the same level of utility (<a class="reference internal" href="#fig-cobb-douglas-ic"><span class="std std-numref">Fig. 17</span></a>). Thus, decision-makers are <em>indifferent</em> to the consumption of different combinations of goods (or services) on an indifference curve.</p>
<figure class="align-default" id="fig-cobb-douglas-ic">
<a class="reference internal image-reference" href="../_images/Fig-CobbDouglas-IndifferenceCurves-Sqrt.pdf"><img alt="../_images/Fig-CobbDouglas-IndifferenceCurves-Sqrt.pdf" src="../_images/Fig-CobbDouglas-IndifferenceCurves-Sqrt.pdf" style="height: 400px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 17 </span><span class="caption-text">Two-dimensional indifference curves were generated using the Cobb–Douglas utility function with <span class="math notranslate nohighlight">\(\alpha_{1} = \alpha_{2} = 0.5\)</span>. The decision maker is indifferent to a choice between point <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(B\)</span>, i.e., <span class="math notranslate nohighlight">\(A\sim{B}\)</span> or <span class="math notranslate nohighlight">\(C\sim{D}\)</span>. However, the decision maker strictly prefers <span class="math notranslate nohighlight">\(C\)</span> and <span class="math notranslate nohighlight">\(D\)</span> compared to <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(B\)</span>, i.e., <span class="math notranslate nohighlight">\(C\sim{D}\succ{A}\sim{B}\)</span>.</span><a class="headerlink" href="#fig-cobb-douglas-ic" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>For example, the decision agent with the Cobb–Douglas utility function shown in (<a class="reference internal" href="#fig-cobb-douglas-ic"><span class="std std-numref">Fig. 17</span></a>) is <em>indifferent</em> to a choice between <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(B\)</span>, but strictly prefers <span class="math notranslate nohighlight">\(C\)</span> and <span class="math notranslate nohighlight">\(D\)</span> to either <span class="math notranslate nohighlight">\(A\)</span> or <span class="math notranslate nohighlight">\(B\)</span>.</p>
<p>Sample code to compute the two-dimensional indifference curve for a Cobb–Douglas utility function with <span class="math notranslate nohighlight">\(\alpha_{1} = \alpha_{2} = 0.5\)</span>:</p>
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="c"># initialize</span>
<span class="n">α₁</span> <span class="o">=</span> <span class="mf">0.5</span> 
<span class="n">α₂</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">α₁</span>

<span class="c"># Storage: holds indifference curves </span>
<span class="n">results</span> <span class="o">=</span> <span class="kt">Dict</span><span class="p">{</span><span class="kt">Int64</span><span class="p">,</span><span class="kt">Array</span><span class="p">{</span><span class="kt">Float64</span><span class="p">,</span><span class="mi">2</span><span class="p">}}()</span>

<span class="c"># Set values for the good and service 1</span>
<span class="n">X1</span> <span class="o">=</span> <span class="n">range</span><span class="p">(</span><span class="mf">0.001</span><span class="p">,</span><span class="n">stop</span><span class="o">=</span><span class="mf">100.0</span><span class="p">,</span><span class="n">step</span> <span class="o">=</span> <span class="mf">0.001</span><span class="p">)</span> <span class="o">|&gt;</span> <span class="n">collect</span><span class="p">;</span>
<span class="n">d</span> <span class="o">=</span> <span class="n">length</span><span class="p">(</span><span class="n">X1</span><span class="p">);</span>

<span class="c"># Set utility values</span>
<span class="n">U</span> <span class="o">=</span> <span class="p">[</span><span class="mf">12.0</span><span class="p">,</span> <span class="mf">24.0</span><span class="p">,</span> <span class="mf">36.0</span><span class="p">,</span> <span class="mf">48.0</span><span class="p">];</span>
<span class="n">n</span> <span class="o">=</span> <span class="n">length</span><span class="p">(</span><span class="n">U</span><span class="p">);</span>

<span class="c"># simulation loop</span>
<span class="k">for</span> <span class="n">i</span> <span class="o">∈</span> <span class="mi">1</span><span class="o">:</span><span class="n">n</span>

    <span class="c"># Allocate storage for the indifference curve </span>
    <span class="n">Y</span> <span class="o">=</span> <span class="kt">Array</span><span class="p">{</span><span class="kt">Float64</span><span class="p">,</span><span class="mi">2</span><span class="p">}(</span><span class="nb">undef</span><span class="p">,</span><span class="n">d</span><span class="p">,</span><span class="mi">2</span><span class="p">);</span>
    <span class="n">U_val</span> <span class="o">=</span> <span class="n">U</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>

    <span class="c"># compute X2 from the X1 values</span>
    <span class="k">for</span> <span class="n">j</span> <span class="o">∈</span> <span class="mi">1</span><span class="o">:</span><span class="n">d</span>

        <span class="c"># compute the log-transformed utility</span>
        <span class="n">tmp</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">α₂</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="n">log</span><span class="p">(</span><span class="n">U_val</span><span class="p">)</span> <span class="o">-</span> <span class="n">α₁</span><span class="o">*</span><span class="n">log</span><span class="p">(</span><span class="n">X1</span><span class="p">[</span><span class="n">j</span><span class="p">]));</span>

        <span class="c"># store</span>
        <span class="n">Y</span><span class="p">[</span><span class="n">j</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">X1</span><span class="p">[</span><span class="n">j</span><span class="p">];</span>
        <span class="n">Y</span><span class="p">[</span><span class="n">j</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">exp</span><span class="p">(</span><span class="n">tmp</span><span class="p">);</span> <span class="c"># inverse transform</span>
    <span class="k">end</span>

    <span class="c"># store -</span>
    <span class="n">results</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">Y</span><span class="p">;</span>
<span class="k">end</span>
</pre></div>
</div>
</section>
<section id="marginal-rate-of-substitution">
<h3>Marginal rate of substitution<a class="headerlink" href="#marginal-rate-of-substitution" title="Permalink to this headline">#</a></h3>
<p>How much of one good or service a decision maker is willing to trade for another is called the <a class="reference external" href="https://en.wikipedia.org/wiki/Marginal_rate_of_substitution">marginal rate of substution</a> (<a class="reference internal" href="#defn-marginal-rate-of-sub">Definition 47</a>):</p>
<div class="proof definition admonition" id="defn-marginal-rate-of-sub">
<p class="admonition-title"><span class="caption-number">Definition 47 </span> (Marginal Rate of Substitution)</p>
<section class="definition-content" id="proof-content">
<p>A decision maker is analyzing the consumption of different combinations of <span class="math notranslate nohighlight">\(n\)</span> goods or services <span class="math notranslate nohighlight">\(x_{1},\dots,x_{n}\)</span>. The utility
function governing the decision maker <span class="math notranslate nohighlight">\(U(\dots)\)</span> can be expanded by computing the <a class="reference external" href="https://en.wikipedia.org/wiki/Differential_of_a_function#Differentials_in_several_variables">total differential</a> around some point <span class="math notranslate nohighlight">\(\left(x_{1}^{\star},\dots,x_{n}^{\star}\right)\)</span> on an indifference curve with utility <span class="math notranslate nohighlight">\(c\)</span>:</p>
<div class="math notranslate nohighlight" id="equation-eqn-total-differential-ic">
<span class="eqno">(85)<a class="headerlink" href="#equation-eqn-total-differential-ic" title="Permalink to this equation">#</a></span>\[dU = \sum_{i=1}^{n}\left(\frac{\partial{U}}{\partial{x_{i}}}\right)_{\star}dx_{i}\]</div>
<p>The partial derivative of the utility with respect to a change in the consumption of good or service <span class="math notranslate nohighlight">\(i\)</span> is the <a class="reference external" href="https://en.wikipedia.org/wiki/Marginal_utility">marginal utility</a>:</p>
<div class="math notranslate nohighlight">
\[dU = \sum_{i=1}^{n}\left(\text{MU}_{i}^{\star}\right){dx_{i}}\]</div>
<p>The utility <span class="math notranslate nohighlight">\(U(\dots)=c\)</span> on an indifference curve; thus, along an indifference curve <span class="math notranslate nohighlight">\(dU = 0\)</span>. The marginal rate of substitution of good or service <span class="math notranslate nohighlight">\(i\)</span> for <span class="math notranslate nohighlight">\(j\)</span> (all other quantities held constant):</p>
<div class="math notranslate nohighlight" id="equation-eqn-total-differential-ic-constant">
<span class="eqno">(86)<a class="headerlink" href="#equation-eqn-total-differential-ic-constant" title="Permalink to this equation">#</a></span>\[\text{MU}^{\star}_{i}dx_{i} + \text{MU}^{\star}_{j}dx_{j} = 0\qquad{i\neq{j}}\]</div>
<p>can be computed for good <span class="math notranslate nohighlight">\(i\)</span> and <span class="math notranslate nohighlight">\(j\)</span>:</p>
<div class="math notranslate nohighlight" id="equation-eqn-total-differential-ic-mrs">
<span class="eqno">(87)<a class="headerlink" href="#equation-eqn-total-differential-ic-mrs" title="Permalink to this equation">#</a></span>\[\text{MRS}^{\star}_{ij} = -\frac{dx_{j}}{dx_{i}} = \frac{\text{MU}^{\star}_{i}}{\text{MU}^{\star}_{j}}\qquad\forall\left(i,j\right)_{i\neq{j}}\]</div>
</section>
</div></section>
<section id="optimal-choices-and-budgets">
<h3>Optimal choices and budgets<a class="headerlink" href="#optimal-choices-and-budgets" title="Permalink to this headline">#</a></h3>
<p>An optimal decision-making agent <em>maximizes</em> its utility function, i.e., the agent searches for a combination of goods and services that gives the highest satisfaction subject to various constraints, e.g., a budget constraint (<a class="reference internal" href="#eqn-budget-constraint">Definition 48</a>):</p>
<div class="proof definition admonition" id="eqn-budget-constraint">
<p class="admonition-title"><span class="caption-number">Definition 48 </span> (Maximum utility and budget constraints)</p>
<section class="definition-content" id="proof-content">
<p>A decision making agent has a utility function <span class="math notranslate nohighlight">\(U\left(x_{1},\dots,x_{n}\right)\)</span> and <span class="math notranslate nohighlight">\(I\)</span> dollars to spend between <span class="math notranslate nohighlight">\(t\rightarrow{t+dt}\)</span>. An optimal agent maximizes its utility subject to its budget:</p>
<div class="math notranslate nohighlight" id="equation-eqn-max-ulity-problem">
<span class="eqno">(88)<a class="headerlink" href="#equation-eqn-max-ulity-problem" title="Permalink to this equation">#</a></span>\[\begin{split}\begin{eqnarray}
\text{maximize}~\mathcal{O} &amp;=&amp; U\left(x_{1},\dots,x_{n}\right) \\
\text{subject to}~\sum_{i=1}^{n}c_{i}x_{i} &amp; \leq &amp; I\\
\text{and}~x_{i}&amp;\geq&amp;{0}\qquad{i=1,2,\dots,n}
\end{eqnarray}\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(c_{i}\geq{0}~\forall{i}\)</span> denotes the cost of good or service <span class="math notranslate nohighlight">\(i\)</span>, and <span class="math notranslate nohighlight">\(x_{i}\)</span> represents the amount of good or service purchased or consumed by the agent during time period <span class="math notranslate nohighlight">\(t\rightarrow{t+dt}\)</span>.</p>
</section>
</div><p>The problem in <a class="reference internal" href="#eqn-budget-constraint">Definition 48</a> can be solved for the unknown consumption levels of <span class="math notranslate nohighlight">\(x_{i}\)</span> using various techniques. For example, we could use the <a class="reference external" href="https://en.wikipedia.org/wiki/Lagrange_multiplier">method of Lagrange multipliers</a> or a <a class="reference external" href="https://en.wikipedia.org/wiki/Penalty_method">penalty method</a> in combination with any number of heuristic optimization approaches, e.g., <a class="reference external" href="https://en.wikipedia.org/wiki/Simulated_annealing">simulated annealing</a>. Of course, if the utility function in <a class="reference internal" href="#eqn-budget-constraint">Definition 48</a> is linear, we could also use <a class="reference external" href="https://en.wikipedia.org/wiki/Linear_programming">linear programming</a>.</p>
<p>Let’s do an example of a decision between two goods using a Cobb–Douglas utility function subject to a budget constraint (<a class="reference internal" href="#example-utility-max-budget">Example 27</a>):</p>
<div class="proof example dropdown admonition" id="example-utility-max-budget">
<p class="admonition-title"><span class="caption-number">Example 27 </span> (Maximize utility subject to budget)</p>
<section class="example-content" id="proof-content">
<p><strong>Problem</strong>: A decision making agent must decide how much of two goods to consume, <span class="math notranslate nohighlight">\(x_{1}\)</span> and <span class="math notranslate nohighlight">\(x_{2}\)</span>, subject to a budget constraint. Good one costs 18.0 USD per unit, while good two costs 36.0 USD per unit. The agent has 100.0 USD to spend and is governed by a Cobb–Douglas utility function with <span class="math notranslate nohighlight">\(\alpha_{1} = 0.45\)</span> and  <span class="math notranslate nohighlight">\(\alpha_{2} = 0.55\)</span>. Compute the optimal mixture of <span class="math notranslate nohighlight">\(x_{1}\)</span> and <span class="math notranslate nohighlight">\(x_{2}\)</span>.</p>
</section>
</div></section>
</section>
<section id="choices-under-uncertainty">
<span id="content-references-utility-and-uncetain-decisions"></span><h2>Choices under uncertainty<a class="headerlink" href="#choices-under-uncertainty" title="Permalink to this headline">#</a></h2>
<p>In the previous section, we developed tools to make optimal choices when the outcomes were sure, and the level of satisfaction derived from those choices was known, e.g., the utility of purchasing a particular bundle of goods or services could be computed using a utility function. However, in many real-world situations, the assumption of certainty is invalid. For example, betting, buying an insurance policy or investing in a new business, or the stock market all or <em>uncertain</em>.</p>
<p>To understand how optimal agents behave when faced with uncertain situations, we define the <a class="reference external" href="https://en.wikipedia.org/wiki/Von_Neumann%E2%80%93Morgenstern_utility_theorem">von Neumann-Morgenstern theorem</a>, which provides a basis for computing an optimal decision in an uncertain situation.</p>
<section id="the-von-neumann-morgenstern-theorem">
<h3>The von Neumann - Morgenstern theorem<a class="headerlink" href="#the-von-neumann-morgenstern-theorem" title="Permalink to this headline">#</a></h3>
<p>The <a class="reference external" href="https://en.wikipedia.org/wiki/Von_Neumann%E2%80%93Morgenstern_utility_theorem">von Neumann-Morgenstern theorem</a>, also known as the <a class="reference external" href="https://en.wikipedia.org/wiki/Expected_utility_hypothesis">expected utility hypothesis</a>, is a fundamental result in decision theory that provides a framework for making <em>rational choices</em> under uncertainty <span id="id1">[<a class="reference internal" href="../References.html#id2" title="J. von Neumann and O. Morgenstern. Theory of games and economic behavior. Princeton University Press, 1944.">von Neumann and Morgenstern, 1944</a>]</span> (<a class="reference internal" href="#defn-expected-utility-hypothesis">Definition 49</a>):</p>
<div class="proof definition admonition" id="defn-expected-utility-hypothesis">
<p class="admonition-title"><span class="caption-number">Definition 49 </span> (Expected utility hypothesis)</p>
<section class="definition-content" id="proof-content">
<p>An agent chooses amongst <span class="math notranslate nohighlight">\(n\)</span> possible uncertain objects, <span class="math notranslate nohighlight">\(x_{1},\dots,x_{n}\)</span> where object <span class="math notranslate nohighlight">\(k\)</span> has a probability <span class="math notranslate nohighlight">\(p_{k}\)</span> of occuring and a utility payoff of <span class="math notranslate nohighlight">\(U(x_{k})\)</span>. A <em>rational decision maker</em> maximizes the expected utility subject to constraints:</p>
<div class="math notranslate nohighlight" id="equation-eqn-max-expected-ulity-problem">
<span class="eqno">(89)<a class="headerlink" href="#equation-eqn-max-expected-ulity-problem" title="Permalink to this equation">#</a></span>\[\begin{split}\begin{eqnarray}
\text{maximize}~\mathcal{O} &amp;=&amp; \sum_{k=1}^{n}p_{k}U(x_{k}) \\
\text{subject to}~g(x)~&amp; \leq &amp; 0\\
\text{and}~x_{k}&amp;\geq&amp;{0}\qquad{k=1,2,\dots,n}
\end{eqnarray}\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(p_{k}\)</span> denotes the probability of object <span class="math notranslate nohighlight">\(k\)</span>, and <span class="math notranslate nohighlight">\(g(x)\)</span> denotes potentially non-linear constraints governing the objects <span class="math notranslate nohighlight">\(x_{1},\dots,x_{n}\)</span>.</p>
</section>
</div><p>The <a class="reference external" href="https://en.wikipedia.org/wiki/Von_Neumann%E2%80%93Morgenstern_utility_theorem">von Neumann-Morgenstern theorem</a> depends upon an understanding of two critical concepts, random variables, and probability:</p>
<ul class="simple">
<li><p>A <a class="reference external" href="https://en.wikipedia.org/wiki/Random_variable">random variable</a> is a variable <span class="math notranslate nohighlight">\(X\)</span> that takes on different values <span class="math notranslate nohighlight">\(x\)</span> according to the outcome of a random event or process. There are two types of random variables: discrete random variables and continuous random variables. Discrete random variables can take on a countable number of distinct values, while continuous random variables can take on any value in a continuous range.</p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Probability">Probability</a> measures the likelihood that a particular event or outcome will occur and is commonly used to quantify uncertainty in various fields, such as science, engineering, economics, and finance. For a discrete random variable, the likelihood that <span class="math notranslate nohighlight">\(X=x\)</span> is described by a <a class="reference external" href="https://en.wikipedia.org/wiki/Probability_mass_function">Probability Mass Function (PMF)</a> and a <a class="reference external" href="https://en.wikipedia.org/wiki/Probability_density_function">Probability Density Function (PDF)</a> for continuous random variables.</p></li>
</ul>
<section id="probability-mass-functions">
<h4>Probability mass functions<a class="headerlink" href="#probability-mass-functions" title="Permalink to this headline">#</a></h4>
<p>In the case of discrete random variables, for example, dice roles, coin flips etc, the likelihood that <span class="math notranslate nohighlight">\(X=x\)</span> is described by a <a class="reference external" href="https://en.wikipedia.org/wiki/Probability_mass_function">Probability Mass Function (PMF)</a> (<a class="reference internal" href="#defn-pmf">Definition 50</a>):</p>
<div class="proof definition admonition" id="defn-pmf">
<p class="admonition-title"><span class="caption-number">Definition 50 </span> (Probability Mass Function)</p>
<section class="definition-content" id="proof-content">
<p>The probability mass function (PMF) of a discrete random variable <span class="math notranslate nohighlight">\(X\)</span> is a function that specifies the probability of obtaining <span class="math notranslate nohighlight">\(X = x\)</span>, where <span class="math notranslate nohighlight">\(x\)</span> is a particular event in the set of possible events we’re interested in <span class="math notranslate nohighlight">\(\mathcal{F}\subseteq{X\left(\Omega\right)}\)</span>:</p>
<div class="math notranslate nohighlight">
\[p_{X}(x) = P\left(X=x\right)\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathcal{F}\)</span> is the event space, and <span class="math notranslate nohighlight">\(\Omega\)</span> is the sample space. A probability mass function must satisfy the condition:</p>
<div class="math notranslate nohighlight">
\[\sum_{x\in{X(\Omega)}}p_{X}(x)=1\]</div>
</section>
</div><p>Thus, in the context of the <a class="reference external" href="https://en.wikipedia.org/wiki/Von_Neumann%E2%80%93Morgenstern_utility_theorem">von Neumann-Morgenstern theorem</a>, the probability mass function is a weight for discrete random variables which model uncertain payoffs.</p>
<p>In <a class="reference external" href="https://julialang.org">Julia</a>, probability mass (or density) functions can be constructed and sampled using the <a class="reference external" href="https://juliastats.org/Distributions.jl/stable/">Distributions.jl</a> package. Let’s look at a few common probability mass functions.</p>
<section id="bernoulli-random-variable">
<h5>Bernoulli random variable<a class="headerlink" href="#bernoulli-random-variable" title="Permalink to this headline">#</a></h5>
<p>A Bernoulli random variable, the simplest random variable, models a coin flip or some other type of binary
outcome (<a class="reference internal" href="#defn-pmf-bernouli">Definition 51</a>):</p>
<div class="proof definition admonition" id="defn-pmf-bernouli">
<p class="admonition-title"><span class="caption-number">Definition 51 </span> (Bernoulli Random Variable)</p>
<section class="definition-content" id="proof-content">
<p>Let <span class="math notranslate nohighlight">\(X\)</span> be a Bernoulli random variable. Then, the probability mass function of <span class="math notranslate nohighlight">\(X\)</span> is given by:</p>
<div class="math notranslate nohighlight">
\[\begin{split}p_{X}(x) =
\begin{cases}
  p &amp; \text{if } x = 1 \\
  1 - p &amp; \text{if } x = 0
\end{cases}\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(0&lt;p&lt;1\)</span> is called the Bernoulli parameter. For a Bernoulli random variable <span class="math notranslate nohighlight">\(X(\Omega) \in [0,1]\)</span> the expectation is given by:</p>
<div class="math notranslate nohighlight">
\[\mathbb{E}\left[X\right] = p\]</div>
<p>while the variance <span class="math notranslate nohighlight">\(\text{Var}(X)\)</span> is given by:</p>
<div class="math notranslate nohighlight">
\[\text{Var}\left[X\right] = p(1-p)\]</div>
</section>
</div><p>Bernoulli random variables, named after the Swiss mathematician <a class="reference external" href="https://en.wikipedia.org/wiki/Jacob_Bernoulli">Jacob Bernoulli</a>, have two states: either <code class="docutils literal notranslate"><span class="pre">1</span></code> or <code class="docutils literal notranslate"><span class="pre">0</span></code>. The probability of getting <code class="docutils literal notranslate"><span class="pre">1</span></code> is <span class="math notranslate nohighlight">\(p\)</span>, while the likelihood of getting a value of <code class="docutils literal notranslate"><span class="pre">0</span></code> is <span class="math notranslate nohighlight">\(1 − p\)</span>. Bernoulli random variables model many binary events: coin flips (H or T), binary bits (1 or 0), true or false, yes or no, present or absent, etc.</p>
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="c"># load the distributions package, and some other stuff</span>
<span class="k">using</span> <span class="n">Distributions</span>
<span class="k">using</span> <span class="n">Statistics</span>
<span class="k">using</span> <span class="n">PrettyTables</span>

<span class="c"># Details of Bernoulli distribution: </span>
<span class="c"># https://juliastats.org/Distributions.jl/stable/univariate/#Discrete-Distributions</span>

<span class="c"># setup constants -</span>
<span class="n">p</span> <span class="o">=</span> <span class="mf">0.64</span><span class="p">;</span>
<span class="n">number_of_samples</span> <span class="o">=</span> <span class="mi">100</span><span class="p">;</span>

<span class="c"># build a Bernoulli distribution</span>
<span class="n">d</span> <span class="o">=</span> <span class="n">Bernoulli</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>

<span class="c"># sample (check expectation, and variance)</span>
<span class="n">samples</span> <span class="o">=</span> <span class="n">rand</span><span class="p">(</span><span class="n">d</span><span class="p">,</span><span class="n">number_of_samples</span><span class="p">);</span>

<span class="c"># build a table -</span>
<span class="n">data_for_table</span> <span class="o">=</span> <span class="kt">Array</span><span class="p">{</span><span class="kt">Any</span><span class="p">,</span><span class="mi">2</span><span class="p">}(</span><span class="nb">undef</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">table_header</span> <span class="o">=</span> <span class="p">[</span><span class="s">&quot;&quot;</span><span class="p">,</span> <span class="s">&quot;E(X)&quot;</span><span class="p">,</span> <span class="s">&quot;Var(X)&quot;</span><span class="p">]</span>

<span class="c"># row 1: model</span>
<span class="n">data_for_table</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="s">&quot;model&quot;</span>
<span class="n">data_for_table</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">mean</span><span class="p">(</span><span class="n">d</span><span class="p">);</span>
<span class="n">data_for_table</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">]</span> <span class="o">=</span> <span class="n">var</span><span class="p">(</span><span class="n">d</span><span class="p">);</span>

<span class="c"># row 2: samples</span>
<span class="n">data_for_table</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="s">&quot;samples&quot;</span>
<span class="n">data_for_table</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">mean</span><span class="p">(</span><span class="n">samples</span><span class="p">);</span>
<span class="n">data_for_table</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">]</span> <span class="o">=</span> <span class="n">var</span><span class="p">(</span><span class="n">samples</span><span class="p">);</span>
<span class="n">pretty_table</span><span class="p">(</span><span class="n">data_for_table</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="n">table_header</span><span class="p">);</span>
</pre></div>
</div>
</section>
</section>
<section id="binomial-random-variable">
<h4>Binomial random variable<a class="headerlink" href="#binomial-random-variable" title="Permalink to this headline">#</a></h4>
<p>The binomial distribution is the probability of getting exactly <span class="math notranslate nohighlight">\(k\)</span> successes in <span class="math notranslate nohighlight">\(n\)</span> independent Bernoulli trials, e.g., the chance of getting four heads in 6 coin tosses (<a class="reference internal" href="#defn-pmf-binomial">Definition 52</a>):</p>
<div class="proof definition admonition" id="defn-pmf-binomial">
<p class="admonition-title"><span class="caption-number">Definition 52 </span> (Binomial Random Variable)</p>
<section class="definition-content" id="proof-content">
<p>Suppose we perform repeated Bernoulli trials <span class="math notranslate nohighlight">\(X(\Omega) \in [0,1]^n\)</span>, i.e., <span class="math notranslate nohighlight">\(n\)</span> trials of an independent binary experiment. The probability of getting exactly <span class="math notranslate nohighlight">\(k\)</span> successes in <span class="math notranslate nohighlight">\(n\)</span> independent Bernoulli trials is governed by the binomial probability mass function:</p>
<div class="math notranslate nohighlight">
\[p_{X}(k) = \binom{n}{k}p^{k}\left(1-p\right)^{n-k}\qquad{k=0,1,\dots,n}\]</div>
<p>where <span class="math notranslate nohighlight">\(k\)</span> denotes the number of successes in <span class="math notranslate nohighlight">\(n\)</span> independent experiments, the binomial parameter <span class="math notranslate nohighlight">\(0&lt;p&lt;1\)</span> is the probability
of a successful trial and:</p>
<div class="math notranslate nohighlight">
\[\binom{n}{k} = \frac{n!}{k!\left(n-k\right)!}\]</div>
<p>is the binomial coefficient. The expectation of a binomial random variable is given by:</p>
<div class="math notranslate nohighlight">
\[\mathbb{E}\left[X\right] = np\]</div>
<p>while the variance <span class="math notranslate nohighlight">\(\text{Var}(X)\)</span> is given by:</p>
<div class="math notranslate nohighlight">
\[\text{Var}\left[X\right] = np(1-p)\]</div>
</section>
</div><div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="c"># load the distributions package, and some other stuff</span>
<span class="k">using</span> <span class="n">Distributions</span>
<span class="k">using</span> <span class="n">Statistics</span>
<span class="k">using</span> <span class="n">PrettyTables</span>

<span class="c"># Details of Binomial distribution: </span>
<span class="c"># https://juliastats.org/Distributions.jl/stable/univariate/#Distributions.Binomial</span>

<span class="c"># setup constants -</span>
<span class="n">number_of_trials</span> <span class="o">=</span> <span class="mi">100</span><span class="p">;</span>
<span class="n">p</span> <span class="o">=</span> <span class="mf">0.64</span><span class="p">;</span>
<span class="n">number_of_samples</span> <span class="o">=</span> <span class="mi">100</span><span class="p">;</span>

<span class="c"># build a Bernoulli distribution</span>
<span class="n">d</span> <span class="o">=</span> <span class="n">Binomial</span><span class="p">(</span><span class="n">number_of_trials</span><span class="p">,</span><span class="n">p</span><span class="p">)</span>

<span class="c"># sample (check expectation, and variance)</span>
<span class="n">samples</span> <span class="o">=</span> <span class="n">rand</span><span class="p">(</span><span class="n">d</span><span class="p">,</span><span class="n">number_of_samples</span><span class="p">);</span>

<span class="c"># build a table -</span>
<span class="n">data_for_table</span> <span class="o">=</span> <span class="kt">Array</span><span class="p">{</span><span class="kt">Any</span><span class="p">,</span><span class="mi">2</span><span class="p">}(</span><span class="nb">undef</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">table_header</span> <span class="o">=</span> <span class="p">[</span><span class="s">&quot;&quot;</span><span class="p">,</span> <span class="s">&quot;E(X)&quot;</span><span class="p">,</span> <span class="s">&quot;Var(X)&quot;</span><span class="p">]</span>

<span class="c"># row 1: model</span>
<span class="n">data_for_table</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="s">&quot;model&quot;</span>
<span class="n">data_for_table</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">mean</span><span class="p">(</span><span class="n">d</span><span class="p">);</span>
<span class="n">data_for_table</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">]</span> <span class="o">=</span> <span class="n">var</span><span class="p">(</span><span class="n">d</span><span class="p">);</span>

<span class="c"># row 2: samples</span>
<span class="n">data_for_table</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="s">&quot;samples&quot;</span>
<span class="n">data_for_table</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">mean</span><span class="p">(</span><span class="n">samples</span><span class="p">);</span>
<span class="n">data_for_table</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">]</span> <span class="o">=</span> <span class="n">var</span><span class="p">(</span><span class="n">samples</span><span class="p">);</span>
<span class="n">pretty_table</span><span class="p">(</span><span class="n">data_for_table</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="n">table_header</span><span class="p">);</span>
</pre></div>
</div>
<section id="geometric-random-variable">
<h5>Geometric random variable<a class="headerlink" href="#geometric-random-variable" title="Permalink to this headline">#</a></h5>
<p>Geometric random variables are a type of discrete probability distribution that models the number of trials required to obtain the first success in a sequence of independent Bernoulli trials (<a class="reference internal" href="#defn-pmf-geometric">Definition 53</a>):</p>
<div class="proof definition admonition" id="defn-pmf-geometric">
<p class="admonition-title"><span class="caption-number">Definition 53 </span> (Geometric Random Variable)</p>
<section class="definition-content" id="proof-content">
<p>Let <span class="math notranslate nohighlight">\(X\)</span> be a geometric random variable. The probability mass function for a geometric random variable is given by:</p>
<div class="math notranslate nohighlight">
\[p_{X}(k) = (1-p)^{(k-1)}p\qquad{k=1,2,\dots}\]</div>
<p>where <span class="math notranslate nohighlight">\(p\)</span> denotes the geometric parameter <span class="math notranslate nohighlight">\(0&lt;p&lt;1\)</span>. The expectation of a geometric random variable <span class="math notranslate nohighlight">\(X\)</span> is given by:</p>
<div class="math notranslate nohighlight">
\[\mathbb{E}\left[X\right] = \frac{1}{p}\]</div>
<p>while the variance <span class="math notranslate nohighlight">\(\text{Var}(X)\)</span> is given by:</p>
<div class="math notranslate nohighlight">
\[\text{Var}\left[X\right] = \frac{1-p}{p^2}\]</div>
</section>
</div></section>
<section id="poisson-random-variable">
<h5>Poisson random variable<a class="headerlink" href="#poisson-random-variable" title="Permalink to this headline">#</a></h5>
<p>Poisson random variables are a type of discrete probability distribution that models the number of occurrences of an event in a fixed interval of time or space (<a class="reference internal" href="#defn-pmf-poisson">Definition 54</a>):</p>
<div class="proof definition admonition" id="defn-pmf-poisson">
<p class="admonition-title"><span class="caption-number">Definition 54 </span> (Poisson Random Variable)</p>
<section class="definition-content" id="proof-content">
<p>Let <span class="math notranslate nohighlight">\(X\)</span> be a Poisson random variable. The probability mass function for a Poisson random variable is given by:</p>
<div class="math notranslate nohighlight">
\[p_{X}(x) = \frac{\lambda^{x}}{x!}\exp\left(-\lambda\right)\]</div>
<p>where <span class="math notranslate nohighlight">\(\lambda&gt;0\)</span> denotes the Poisson parameter, and <span class="math notranslate nohighlight">\(!\)</span> denotes the factorial function. The expectation of a Poisson random variable <span class="math notranslate nohighlight">\(X\)</span> is given by:</p>
<div class="math notranslate nohighlight">
\[\mathbb{E}\left[X\right] = \lambda\]</div>
<p>while the variance <span class="math notranslate nohighlight">\(\text{Var}(X)\)</span> is given by:</p>
<div class="math notranslate nohighlight">
\[\text{Var}\left[X\right] = \lambda\]</div>
</section>
</div><p>Poisson random variables estimate how likely something will happen <span class="math notranslate nohighlight">\(x\)</span> number of times in a fixed interval, e.g., the number of car crashes in a city of a given size or the number of cheeseburgers sold at a fast-food chain on a Friday night.</p>
</section>
</section>
<section id="expectation">
<h4>Expectation<a class="headerlink" href="#expectation" title="Permalink to this headline">#</a></h4>
<p>The <a class="reference external" href="https://en.wikipedia.org/wiki/Expected_value">expectation</a> of a discrete random variable <span class="math notranslate nohighlight">\(X\)</span> measures the central tendency of the values of that random variable (<a class="reference internal" href="#defn-discrete-random-variable-expectation">Definition 55</a>):</p>
<div class="proof definition admonition" id="defn-discrete-random-variable-expectation">
<p class="admonition-title"><span class="caption-number">Definition 55 </span> (Expectation discrete random variable)</p>
<section class="definition-content" id="proof-content">
<p>Let <span class="math notranslate nohighlight">\(X\)</span> denote a discere random variable with the probability space <span class="math notranslate nohighlight">\(\left(\Omega,\mathcal{F},P\right)\)</span>, where <span class="math notranslate nohighlight">\(\Omega\)</span> denotes the sample space, <span class="math notranslate nohighlight">\(\mathcal{F}\)</span> denotes the event space, and <span class="math notranslate nohighlight">\(P\)</span> denotes the probability measure. Then, the expected value of the random variable <span class="math notranslate nohighlight">\(X\)</span> is given by:</p>
<div class="math notranslate nohighlight" id="equation-eqn-expectation">
<span class="eqno">(90)<a class="headerlink" href="#equation-eqn-expectation" title="Permalink to this equation">#</a></span>\[\mathbb{E}\left[X\right] = \sum_{x\in\Omega}xp_{X}(x)\]</div>
<p>where <span class="math notranslate nohighlight">\(x\)</span> denotes a value for the discrete random variable <span class="math notranslate nohighlight">\(X\)</span>, and <span class="math notranslate nohighlight">\(p_{X}(x)\)</span> denotes the probability of <span class="math notranslate nohighlight">\(X=x\)</span>. The value of <span class="math notranslate nohighlight">\(p_{X}(x)\)</span> is governed by a <a class="reference external" href="https://en.wikipedia.org/wiki/Probability_mass_function">Probability Mass Function (PMF)</a>.</p>
</section>
</div><p>The expectation of a discrete random variable has a few interesting properties (<a class="reference internal" href="#obs-expectation-props">Observation 10</a>):</p>
<div class="proof observation admonition" id="obs-expectation-props">
<p class="admonition-title"><span class="caption-number">Observation 10 </span> (Properties of expectation)</p>
<section class="observation-content" id="proof-content">
<p>The expectation of a random variable <span class="math notranslate nohighlight">\(X\)</span> has several useful (and important) properties:</p>
<ol class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbb{E}\left(c\right) = c\)</span> for any constant <span class="math notranslate nohighlight">\(c\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbb{E}\left(cX\right) = c\times\mathbb{E}\left(X\right)\)</span> for any constant <span class="math notranslate nohighlight">\(c\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbb{E}\left(g(X)\right) = \sum_{x\in{X(\Omega)}}g(x)p_{X}(x)\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbb{E}\left(g(X)+h(X)\right) = \mathbb{E}(g(X)) + \mathbb{E}(h(X))\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbb{E}\left(X+c\right) = \mathbb{E}(X) + c\)</span> for any constant <span class="math notranslate nohighlight">\(c\)</span></p></li>
</ol>
</section>
</div></section>
<section id="variance">
<h4>Variance<a class="headerlink" href="#variance" title="Permalink to this headline">#</a></h4>
<p>The <a class="reference external" href="https://en.wikipedia.org/wiki/Variance">variance</a> measures the expected dispersion for
individual values of a random variable <span class="math notranslate nohighlight">\(X\)</span>, i.e., the average distance that values of <span class="math notranslate nohighlight">\(X\)</span> are spread out from their expected value (<a class="reference internal" href="#defn-discrete-random-variable-variance">Definition 56</a>):</p>
<div class="proof definition admonition" id="defn-discrete-random-variable-variance">
<p class="admonition-title"><span class="caption-number">Definition 56 </span> (Expectation discrete random variable)</p>
<section class="definition-content" id="proof-content">
<p>Let <span class="math notranslate nohighlight">\(X\)</span> denote a discrete random variable with the probability space <span class="math notranslate nohighlight">\(\left(\Omega,\mathcal{F},P\right)\)</span>, where <span class="math notranslate nohighlight">\(\Omega\)</span> denotes the sample space, <span class="math notranslate nohighlight">\(\mathcal{F}\)</span> denotes the event space, and <span class="math notranslate nohighlight">\(P\)</span> denotes the probability measure. Then, the variance of the random variable <span class="math notranslate nohighlight">\(X\)</span> is given by:</p>
<div class="math notranslate nohighlight" id="equation-eqn-variance">
<span class="eqno">(91)<a class="headerlink" href="#equation-eqn-variance" title="Permalink to this equation">#</a></span>\[\text{Var}(X) = \mathbb{E}\Bigl[(X-\mu)^{2}\Bigr]\]</div>
<p>where <span class="math notranslate nohighlight">\(\mu = \mathbb{E}(X)\)</span> denotes the expected value of the random variable <span class="math notranslate nohighlight">\(X\)</span>.</p>
</section>
</div><p>The variance of a discrete random variable has a few interesting properties (<a class="reference internal" href="#obs-variances-var">Observation 11</a>):</p>
<div class="proof observation admonition" id="obs-variances-var">
<p class="admonition-title"><span class="caption-number">Observation 11 </span> (Properties of variance)</p>
<section class="observation-content" id="proof-content">
<p>The variance of a random variable <span class="math notranslate nohighlight">\(X\)</span> has a few interesting (and important) properties:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\text{Var}(X) = \mathbb{E}\left(X^{2}\right) - \mathbb{E}\left(X\right)^2\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\text{Var}(cX) = {c^2}\text{Var}(X)\)</span> for any constant <span class="math notranslate nohighlight">\(c\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\text{Var}(X+c) = \text{Var}(X)\)</span> for any constant <span class="math notranslate nohighlight">\(c\)</span></p></li>
</ul>
</section>
</div><p>The more common quantity that is used to measure dispersion, the standard deviation <span class="math notranslate nohighlight">\(\sigma\)</span>, is related to the variance: <span class="math notranslate nohighlight">\(\sigma_{X} = \sqrt{\text{Var}(X)}\)</span>.</p>
</section>
</section>
</section>
</section>
<hr class="docutils" />
<section class="tex2jax_ignore mathjax_ignore" id="summary">
<h1>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">#</a></h1>
<p>Uncertain decisions are those that involve risk or ambiguity. Uncertain decisions arise in many situations, such as investing in the stock market, choosing a career path, making technical choices, or deciding whether to pursue a romantic relationship.</p>
<p>In this lecture, we introduced tools to model and analyze simple uncertain decisions:</p>
<ul class="simple">
<li><p><a class="reference internal" href="#content-references-utility-and-utlity-max"><span class="std std-ref">Utility maximization</span></a> is the process of selecting the option that provides the highest level of satisfaction, or utility, based on the individual’s preferences and constraints. This concept is often used in economics to model consumer behavior and in decision theory to analyze choices under uncertainty.</p></li>
<li><p><a class="reference internal" href="#content-references-utility-and-uncetain-decisions"><span class="std std-ref">Choices under uncertainty</span></a> are decision-making situations where the outcomes of different options are unknown or uncertain. These types of decisions often involve risk and involve balancing the potential rewards and risks of different options. To make optimal choices under uncertainty, decision-makers may use probabilistic tools such as expected utility theory to analyze the expected outcomes of different options.</p></li>
</ul>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "julia-1.8"
        },
        kernelOptions: {
            kernelName: "julia-1.8",
            path: "./unit-4-decisions"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'julia-1.8'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="decisions-landing.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">The Decision Problem: Probability, Random Processes, and Decisions</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="mdp.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Markov Decision Processes</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Varner<br/>
  
      &copy; Copyright 2023.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>